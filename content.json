{"meta":{"title":"skyitachi's blog","subtitle":null,"description":"一定要有输出","author":"skyitachi","url":"https://skyitachi.github.io","root":"/"},"pages":[],"posts":[{"title":"ES和Lucene之间的CRUD操作映射","slug":"ES和Lucene之间的CRUD操作映射","date":"2024-05-10T16:00:00.000Z","updated":"2024-07-06T16:00:00.000Z","comments":true,"path":"2024/05/11/ES和Lucene之间的CRUD操作映射/","permalink":"https://skyitachi.github.io/2024/05/11/ES%E5%92%8CLucene%E4%B9%8B%E9%97%B4%E7%9A%84CRUD%E6%93%8D%E4%BD%9C%E6%98%A0%E5%B0%84/","excerpt":"","text":"前言在ES中我们经常使用的数据格式json，ES也支持常见的CRUD操作，这里我们主要介绍写入相关的操作（创建，更新，删除），ES的底层存储引擎是Lucene，Lucene也有相关创建更新删除的操作，但是Lucene是没有显示的根据主键更新文档的api的，本文主要介绍的是在ES有_id的情况下，ES是如何基于Lucene实现增删改的操作的，其中的数据模型又是如何映射的. ps: 本文不考虑ES中的数据类型到Lucene中的数据类型的映射（Field），所有的代码片段都是基于以下给定的类型映射 Name ES type Lucene Field item_id keyword StringField name keyword StringField color keyword StringField lucene 如何基于id（主键）部分更新文档 (基于lucene 9.7.0)12345 &lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-core&lt;/artifactId&gt; &lt;version&gt;9.7.0&lt;/version&gt;&lt;/dependency&gt; 1. 创建文档123456789101112131415161718public static void createDocuments(IndexWriter indexWriter) throws IOException &#123; Document doc1 = new Document(); doc1.add(new StringField(&quot;item_id&quot;, &quot;1&quot;, Field.Store.YES )); doc1.add(new StringField(&quot;name&quot;, &quot;item1&quot;, Field.Store.YES)); doc1.add(new StringField(&quot;color&quot;, &quot;red&quot;, Field.Store.YES)); Document doc2 = new Document(); doc2.add(new StringField(&quot;item_id&quot;, &quot;2&quot;, Field.Store.YES)); doc2.add(new StringField(&quot;name&quot;, &quot;item2&quot;, Field.Store.YES)); doc2.add(new StringField(&quot;color&quot;, &quot;blue&quot;, Field.Store.YES)); indexWriter.addDocument(doc1); indexWriter.addDocument(doc2); indexWriter.commit(); indexWriter.flush();&#125; 2. 读取文档验证写入1234567891011121314public static void getDocumentById(IndexReader reader, IndexSearcher searcher, String itemId) throws IOException &#123; Query query = new TermQuery(new Term(&quot;item_id&quot;, itemId)); TopDocs topdocs = searcher.search(query, 10); assert topdocs.totalHits.value == 1; for (ScoreDoc doc: topdocs.scoreDocs) &#123; int docId = doc.doc; Document fullDoc = getDocumentByDocId(reader, docId); fullDoc.getFields().forEach(field -&gt; &#123; System.out.println(&quot; &quot; + field.name() + &quot;: &quot; + field.stringValue()); &#125;); &#125;&#125; 123456789// item_id = &quot;1&quot;getDocumentById(reader, searcher, &quot;1&quot;);// item_id: 1// name: item1// color: redgetDocumentById(reader, searcher, &quot;2&quot;);// item_id: 2// name: item2// color: blue 3. 部分更新文档123456789public static void partialUpdateDocumentNameByItemId(IndexWriter writer, String itemId, String newName) throws IOException &#123; Document doc = new Document(); doc.add(new StringField(&quot;name&quot;, newName, Field.Store.YES)); // important: 这个作为主键的Term一定要带上 doc.add(new StringField(&quot;item_id&quot;, itemId, Field.Store.YES)); Term mainTerm = new Term(&quot;item_id&quot;, itemId); writer.updateDocument(mainTerm, doc);&#125; 4. 验证更新文档123456789101112131415161718partialUpdateDocumentNameByItemId(indexWriter, &quot;1&quot;, &quot;item1_updated&quot;);partialUpdateDocumentNameByItemId(indexWriter, &quot;2&quot;, &quot;item2_updated&quot;);indexWriter.commit();indexWriter.flush();indexReader = DirectoryReader.open(readDirectory);indexSearcher = new IndexSearcher(indexReader);getDocumentById(indexSearcher, &quot;1&quot;);indexReader = DirectoryReader.open(readDirectory);indexSearcher = new IndexSearcher(indexReader);getDocumentById(indexSearcher, &quot;2&quot;);//// name: item1_updated// item_id: 1// name: item2_updated// item_id: 2 结论： 由于在partialUpdateDocumentNameByItemId 中只写了item_id和name属性（符合update的直觉），但是可以看出Lucene把updateDocument中的doc对象当成了最新且完整的mainTerm对应的doc，这就导致了虽然我们目的是部分更新，但是会丢失没有写入（没有变化）的那些属性，这个例子也可以看出Lucene本质上是用新文档覆盖旧文档的形式，用一个可以代表主键的Term做关联，来实现部分更新字段的目的，这个和一般RDBMS的存储模型有点区别. 5. 完全更新所有字段（不变的field也要加入将要更新的document中）123456789public static void fullUpdateDocumentNameByItemId(IndexWriter writer, String itemId, String newName, String oldColor) throws IOException &#123; Document doc = new Document(); doc.add(new StringField(&quot;name&quot;, newName, Field.Store.YES)); doc.add(new StringField(&quot;item_id&quot;, itemId, Field.Store.YES)); doc.add(new StringField(&quot;color&quot;, oldColor, Field.Store.YES)); Term mainTerm = new Term(&quot;item_id&quot;, itemId); writer.updateDocument(mainTerm, doc);&#125; 6. 验证完全更新123456789101112131415161718192021fullUpdateDocumentNameByItemId(indexWriter, &quot;1&quot;, &quot;item1_updated&quot;, &quot;red&quot;);fullUpdateDocumentNameByItemId(indexWriter, &quot;2&quot;, &quot;item2_updated&quot;, &quot;blue&quot;);indexWriter.commit();indexWriter.flush();indexReader = DirectoryReader.open(readDirectory);indexSearcher = new IndexSearcher(indexReader);getDocumentById(indexSearcher, &quot;1&quot;);indexReader = DirectoryReader.open(readDirectory);indexSearcher = new IndexSearcher(indexReader);getDocumentById(indexSearcher, &quot;2&quot;);// output// name: item1_updated// item_id: 1// color: red// name: item2_updated// item_id: 2// color: blue 7. 删除文档1234public static void deleteDocument(IndexWriter writer, String itemId) throws IOException &#123; Term mainTerm = new Term(&quot;item_id&quot;, itemId); writer.deleteDocuments(mainTerm);&#125; 8. 验证删除文档12345getDocumentById(indexSearcher, &quot;1&quot;);getDocumentById(indexSearcher, &quot;2&quot;);// cannot found 1// cannot found 2 结论： 必须将原始文档的所有字段全部获取到再用updateDocument的方式更新，才能实现我们预期中部分更新字段的目的，可以看到成本还是比较高的 由于Lucene的这种机制也导致了，ES的CRUD模型中需要实现一些额外的机制才能使用到Lucene的能力 ES中的操作ES mapping12345678910111213141516PUT /my_index&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;item_id&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;name&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;color&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125; &#125; &#125;&#125; 1. 创建文档12345678910111213PUT my_index/_doc/1&#123; &quot;item_id&quot;: &quot;1&quot;, &quot;name&quot;:&quot;item1&quot;, &quot;color&quot;: &quot;red&quot;&#125;PUT my_index/_doc/2&#123; &quot;item_id&quot;: &quot;2&quot;, &quot;name&quot;:&quot;item2&quot;, &quot;color&quot;: &quot;blue&quot;&#125; 2. 获取文档123456789101112131415161718192021222324252627GET my_index/_search// output&#123; ... &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;my_index&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;item_id&quot;: &quot;1&quot;, &quot;name&quot;: &quot;item1&quot;, &quot;color&quot;: &quot;red&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;my_index&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;item_id&quot;: &quot;2&quot;, &quot;name&quot;: &quot;item2&quot;, &quot;color&quot;: &quot;blue&quot; &#125; &#125; ]&#125; 3.部分更新12345678910111213POST my_index/_update/1&#123; &quot;doc&quot;: &#123; &quot;name&quot;: &quot;item1_updated&quot; &#125;&#125;POST my_index/_update/2&#123; &quot;doc&quot;: &#123; &quot;name&quot;: &quot;item2_updated&quot; &#125;&#125; 4.获取部分更新后的文档123456789101112131415161718192021222324252627GET my_index/_search// output&#123; ... &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;my_index&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;item_id&quot;: &quot;1&quot;, &quot;name&quot;: &quot;item1_updated&quot;, &quot;color&quot;: &quot;red&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;my_index&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;item_id&quot;: &quot;2&quot;, &quot;name&quot;: &quot;item2_updated&quot;, &quot;color&quot;: &quot;blue&quot; &#125; &#125; ]&#125; 说明: 可以看ES中部分更新是可以正常的工作的, 原因就在于ES在处理update的时候会自动拉取原始文档的所有字段和新的更新的字段组合成一份完整的新的全量字段的文档，再去更新Lucene 5. 完整更新所有字段1234567891011121314151617// 方式一POST my_index/_update/1&#123; &quot;doc&quot;: &#123; &quot;name&quot;: &quot;item1_updated&quot;, &quot;item_id&quot;: &quot;1&quot;, &quot;color&quot;: &quot;red&quot; &#125;&#125;// 方式二PUT my_index/_doc/1&#123; &quot;item_id&quot;: &quot;1&quot;, &quot;name&quot;:&quot;item1_update_by_put&quot;, &quot;color&quot;: &quot;red&quot;&#125; 6. 验证完全更新123456789101112131415161718192021222324252627GET my_index/_search// output&#123; ... &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;my_index&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;item_id&quot;: &quot;1&quot;, &quot;name&quot;: &quot;item1_update_by_put&quot;, &quot;color&quot;: &quot;red&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;my_index&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;item_id&quot;: &quot;2&quot;, &quot;name&quot;: &quot;item2_updated&quot;, &quot;color&quot;: &quot;blue&quot; &#125; &#125; ]&#125; 7. 删除文档12DELETE my_index/_doc/1DELETE my_index/_doc/2 8. 验证删除文档12345678GET my_index/_search// output&#123; ... &quot;hits&quot;: []&#125; ES如何在Lucene的基础上实现基于主键(_id)的删改 ES 使用_id的内部字段作为文档的主键，这个_id可以用户指定，上面的例子中item_id就是对应了_id，Lucene中没有主键的概念，所以需要使用_id 作为一个独特的Term的维持文档的唯一性, 后续的更新, 删除也是和_id对应的Term绑定. Lucene的创建操作不具备幂等性（addDocument）指定了Term之后，这个Term下可以关联N个document，不具备唯一性. ES 在部分字段的更新中，自己封装了一层获取原始文档的操作，之后使用update的方式更新Lucene. ES 在删除文档操作中，使用_id对应的Term 去调用Lucene的API. ES 在创建文档操作中，PUT 相同_id的文档 同样能保持唯一性, 通常情况下ES也是用Lucene update的方式实现创建的请求. 总结 Lucene整体是一个Append Only的存储引擎，且没有主键的概念. ES 本身封装了一系列的操作使得整个CRUD操作更加方便使用，这也不可避免的带了一些额外的开销，通过理解这些操作的底层原理，有助于我们做出一些最佳实践的选择.","categories":[],"tags":[{"name":"ES, Lucene, elasticsearch","slug":"ES-Lucene-elasticsearch","permalink":"https://skyitachi.github.io/tags/ES-Lucene-elasticsearch/"}]},{"title":"Golang 中[]byte, string和[]rune的相互转化的底层原理和剖析","slug":"golang_slice","date":"2021-02-21T02:15:38.000Z","updated":"2021-02-21T02:15:38.000Z","comments":true,"path":"2021/02/21/golang_slice/","permalink":"https://skyitachi.github.io/2021/02/21/golang_slice/","excerpt":"","text":"Golang 中[]byte, string和[]rune的相互转化的底层原理和剖析在golang中有些场景经常会用到[]byte和string的相互转化，尤其是在使用json.Marshal和json.Unmarshal的时候，经常会遇到需要这种转化。 本文主要说明以下内容： 几种类型相互转化的方法和性能分析 这些类型的底层存储 代码gist 相互转化[]byte和string的相互转化string -&gt; []byte1234567891011121314151617181920212223242526func BenchmarkStringToByteSlice(b *testing.B) &#123; s := genString(10000) b.ReportAllocs() for i := 0; i &lt; b.N; i++ &#123; bs := []byte(s) if len(bs) != len(s) &#123; b.Error(&quot;error&quot;) &#125; &#125;&#125;func BenchmarkStringToByteSliceUnsafe(b *testing.B) &#123; s := genString(10000) b.ReportAllocs() for i := 0; i &lt; b.N; i++ &#123; l := len(s) bs := *(*[]byte)(unsafe.Pointer(&amp;reflect.SliceHeader&#123; Data: (*(*reflect.StringHeader)(unsafe.Pointer(&amp;s))).Data, Len: l, Cap: l, &#125;)) if len(bs) != len(s) &#123; b.Error(&quot;error&quot;) &#125; &#125;&#125; 第一种使用[]byte这种直接转化，也是我们常用的方式，第二种是使用unsafe的方式。这两种区别就在于一个是重新分配了内存，另一个是复用了原来的内存。 benchmark的结果也验证了这一点 12345678910go test -run=BenchmarkStringToByteSlice -bench=StringToByteSlice# go-demo.testgoos: darwingoarch: amd64pkg: go-demoBenchmarkStringToByteSlice-12 1164224 964 ns/op 10285 B/op 1 allocs/opBenchmarkStringToByteSliceUnsafe-12 1000000000 0.380 ns/op 0 B/op 0 allocs/opPASSok go-demo 2.089s []byte -&gt; string12345678910111213141516171819202122func BenchmarkSliceByteToString(b *testing.B) &#123; bs := genSliceByte(100) b.ReportAllocs() for i := 0; i &lt; b.N; i++ &#123; s := string(bs) if len(s) != len(bs) &#123; b.Error(&quot;error&quot;) &#125; &#125;&#125;func BenchmarkSliceByteToStringUnsafe(b *testing.B) &#123; bs := genSliceByte(100) b.ReportAllocs() for i := 0; i &lt; b.N; i++ &#123; s := *(*string)(unsafe.Pointer(&amp;bs)) if len(s) != len(bs) &#123; b.Log(&quot;slice: &quot;, len(bs), &quot; string: &quot;, len(s)) b.Error(&quot;error: &quot;) &#125; &#125;&#125; benchmark 结果 12345678910go test -run=BenchmarkSliceByteToString -bench=SliceByteToString# go-demo.testgoos: darwingoarch: amd64pkg: go-demoBenchmarkSliceByteToString-12 35913873 32.4 ns/op 112 B/op 1 allocs/opBenchmarkSliceByteToStringUnsafe-12 1000000000 0.253 ns/op 0 B/op 0 allocs/opPASSok go-demo 3.796s string和[]rune的相互转化string和rune的相互转化其实和上面类似，主要是[]rune对应的[]byte数组长度需要计算下，这里就只贴一个[]rune到string的转化了 123456789101112131415161718func BenchmarkSliceRuneToStringUnsafe(b *testing.B) &#123; bs := genSliceRune(100) s1 := string(bs) b.ReportAllocs() for i := 0; i &lt; b.N; i++ &#123; var l int for _, r := range bs &#123; l += utf8.RuneLen(r) &#125; s := *(*string)(unsafe.Pointer(&amp;reflect.StringHeader&#123; Data: (*(*reflect.SliceHeader)(unsafe.Pointer(&amp;bs))).Data, Len: l, &#125;)) if len(s1) != len(s) &#123; b.Error(&quot;error&quot;) &#125; &#125;&#125; String和Slice的底层存储分析reflect.SliceHeader 和reflect.StringHeader123456789type StringHeader struct &#123; Data uintptr Len int&#125;type SliceHeader struct &#123; Data uintptr Len int Cap int&#125; 两者类型基本一样，Slice多了一个Cap，其实这也决定了[]byte可以直接使用指针强转成string，但是反过来却不行 slice的底层存储12345type slice struct &#123; array unsafe.Pointer len int cap int&#125; 以汇编的形式看下slice的底层结构1234package pkg// var data = make([]int, 0, 10)var data = []int&#123;1, 2&#125; 12345678910go tool compile -S pkg.gogo.cuinfo.packagename. SDWARFINFO dupok size=0 0x0000 70 6b 67 pkg&quot;&quot;.data SDATA size=24 0x0000 00 00 00 00 00 00 00 00 02 00 00 00 00 00 00 00 ................ 0x0010 02 00 00 00 00 00 00 00 ........ rel 0+8 t=1 &quot;&quot;..stmp_0+0&quot;&quot;..stmp_0 SNOPTRDATA size=16 0x0000 01 00 00 00 00 00 00 00 02 00 00 00 00 00 00 00 ................... 可以看到””.data 对应的是size是24（8byte的指针，len和cap各自8byte），slice里的内容是两个int对应的就是，””.stmp_0 里的内容 进一步分析data对应的二进制 data+8是02 00 ... ，对应len data+16是02 00 对应cap 整个slice struct在内存里是紧凑分布的，所以我们可以进行指针类的强制转化，类似于c++中reinterpret_cast string的底层结构1234package pkgvar testStr = &quot;abc&quot; 1234567go.cuinfo.packagename. SDWARFINFO dupok size=0 0x0000 70 6b 67 pkggo.string.&quot;abc&quot; SRODATA dupok size=3 0x0000 61 62 63 abc&quot;&quot;.testStr SDATA size=16 0x0000 00 00 00 00 00 00 00 00 03 00 00 00 00 00 00 00 ................ rel 0+8 t=1 go.string.&quot;abc&quot;+0 和上文的slice很类似，size变成了16而已 Fat Pointer像slice这种结构在c中常被称为fatpointer，感兴趣的同学可以参考Go Slices are Fat Pointers 总结 介绍了golang中string，[]byte和[]rune的转化及简单的性能分析 slice在golang中的底层存储","categories":[],"tags":[{"name":"golang slice","slug":"golang-slice","permalink":"https://skyitachi.github.io/tags/golang-slice/"}]},{"title":"二分法的两种实现","slug":"二分法的两种实现","date":"2020-04-14T14:15:38.000Z","updated":"2020-04-14T14:11:39.000Z","comments":true,"path":"2020/04/14/二分法的两种实现/","permalink":"https://skyitachi.github.io/2020/04/14/%E4%BA%8C%E5%88%86%E6%B3%95%E7%9A%84%E4%B8%A4%E7%A7%8D%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"前言虽然二分搜索很简单（在无重复的有序数组上）,但是也有很多值得注意的地方，而且有两种完全不同的写法（两种完全不同的功能） lower bound 找出大于等于target的最小数组下标, 不存在的情况下返回-1 123456789101112131415161718func lower_bound(a []int, target int) int &#123; l := 0 h := len(a) - 1 for l &lt; h &#123; m := l + (h - l) / 2 if a[m] &gt;= target &#123; h = m &#125; else &#123; // l肯定可以取到h值，所以不需要使用向上取整计算m值 l += 1 &#125; &#125; if a[l] &gt;= target &#123; return l &#125; return -1&#125; upper bound 找出小于等于target的最大数组下标 1234567891011121314151617func upper_bound(a []int, target int) int &#123; l := 0 h := len(a) - 1 for l &lt; h &#123; m := l + (h - l + 1) / 2 if a[m] &lt;= target &#123; // l 要能够取到h值，就必须保证m使用向上取整计算, (h - l + 1) / 2 就是这么来的 l = m &#125; else &#123; h = m - 1 &#125; &#125; if a[l] &lt;= target &#123; return l &#125; return -1&#125; 注意点 计算mid的时候不能发生溢出 数组下标不能越界","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://skyitachi.github.io/tags/algorithm/"}]},{"title":"dubbo-go support protobuf","slug":"dubbo-go-protobuf-support","date":"2019-12-29T16:00:00.000Z","updated":"2019-12-29T16:00:00.000Z","comments":true,"path":"2019/12/30/dubbo-go-protobuf-support/","permalink":"https://skyitachi.github.io/2019/12/30/dubbo-go-protobuf-support/","excerpt":"","text":"主要用法 和grpc中使用protobuf生成代码基本一致（至少在形式上）,直接看例子吧 123456789├── go-client│ ├── client.go│ ├── client.yml├── go-server│ ├── main.go│ └── server.yml└── user ├── user.pb.go └── user.proto 1234567891011121314151617syntax = &quot;proto3&quot;;package user;service UserProvider &#123; rpc GetUser (UserRequest) returns (UserReply) &#123;&#125;&#125;message UserRequest &#123; string id = 1;&#125;message UserReply &#123; string id = 1; string name = 2; int32 age = 3;&#125; 使用protoc-gen-dubbogo插件生成dubbogo的代理 1protoc --plugin=&#123;plugin_path&#125; --dubbogo_out=plugins=dubbogo:. user/user.proto client关键代码 1234567user := user.NewUserProvider()reply := user.UserReply&#123;&#125;err := userProvider.GetUser(context.TODO(), &amp;user.UserRequest&#123;Id: &quot;A001&quot;&#125;, &amp;reply)if err != nil &#123; log.Fatal(err)&#125;println(&quot;response result: %+v&quot;, reply) ps: 一切都是熟悉的味道ps: 生成代理的名称需要和reference里配置的一样 server关键代码 12345678910type UserProvider struct &#123; pb.UnimplementedUserProviderServer&#125;func (*UserProvider) GetUser(ctx context.Context, user *pb.UserRequest) (*pb.UserReply, error) &#123; return &amp;pb.UserReply&#123;Id: &quot;001&quot;, Name: &quot;alice&quot;, Age: 18&#125;, nil&#125;// 注册pb.RegisterProvider(new(UserProvider)) 实现原理 在dubbogo抽出一层serialization，任何和serialization相关的之后只要实现Serialize接口就行了，这样是为了更好的实现更多序列化的支持，逻辑上会更合理一些，原有的go hessian2中做了一部分dubbo相关的codec工作，这里我也把它抽到dubbogo中了， 当然hessian2的序列化仍然保留了，这次实现是兼容老版本的。 12345type Serializer interface &#123; Marshal(p DubboPackage) ([]byte, error) Unmarshal([]byte, *DubboPackage) error&#125; 参考了dubbo的protobuf实现，实现了在protobuf层面和java互通（不一定是好事:(） 其他的就是细节了 一些注意点 error的处理和java不太一样，java会把详细的java error stack都返回给客户端，go只会把message传过来，生成一个error 由于java protobuf生成的代理方法名是小写开头(完全搞不明白是为什么)，这在golang中表示私有方法，个人已经提了issue, 所以直接用java的例子是不行的 java protobuf的代理生成的是内部接口，比如xxx$IDemoService, $是url中的一个特殊字符，正好发现了dubbogo的一个注册url的bug 我为什么要支持protobuf protobuf的语言中立性更好，序列化性能也更好 更加符合golang的生态","categories":[],"tags":[{"name":"dubbo, go, protobuf","slug":"dubbo-go-protobuf","permalink":"https://skyitachi.github.io/tags/dubbo-go-protobuf/"}]},{"title":"c++中的传参","slug":"passing-value-in-cpp","date":"2019-08-21T02:30:36.000Z","updated":"2019-08-21T02:30:36.000Z","comments":true,"path":"2019/08/21/passing-value-in-cpp/","permalink":"https://skyitachi.github.io/2019/08/21/passing-value-in-cpp/","excerpt":"","text":"前言最近在用c++写基于libuv的websocket engine的时候发现, 设置callback的参数是一个很有挑战性的工作, 原来觉得c++的复杂在于其模板，oo范式概念的复杂, 现在发现c++的每个方面都很复杂，因为有太多可以通过编译的方式了，我想从传参这个方面切入，让大家了解下c++的复杂（强大）。 ps：本文的传参使基于涉及到动态内存分配对象的传参，一般普通对象的传参基本是不需要考虑这么复杂的(至少我目前这么认为)。 以下是本文中需要传递的参数，一个简单的String, 只保留会讲到的构造函数 1234567891011121314151617class String: &#123; public: String(const char* src): data_(new char[strlen(src) + 1]), size_(strlen(src)) &#123; ::strcpy(data_, src); data_[size_] = 0; &#125; String(const String&amp; lhs): data_(new char[lhs.size() + 1]), size_(lhs.size()) &#123; ::strcpy(data_, lhs.data()); data_[size_] = 0; &#125; // move String(String &amp;&amp;rhs) noexcept: data_(rhs.data_), size_(rhs.size_) &#123; rhs.data_ = nullptr; &#125; &#125;; 我遇到的一个问题是在MessageCallback中，应该使用const String&amp; message还是String&amp;&amp; message, 这两种形参的区别是什么 理解std::move 和右值引用在弄清上述问题之前，还是要从根本上着手，弄清std::move和右值引用。右值引用是c++11中引入的一种新的引用类型，必须要绑定到右值的引用。而std::move的作用是可以把几乎任意值转化成一个右值引用。 123456789101112131415161718void test_passing_value(std::string&amp; s1) &#123; std::cout &lt;&lt; &quot;in the left reference&quot; &lt;&lt; std::endl;&#125;void test_passing_value(std::string&amp;&amp; s1) &#123; std::cout &lt;&lt; &quot;in the right reference&quot; &lt;&lt; std::endl;&#125;std::string s1 = &quot;hello&quot;;std::string &amp;sr = s1;test_passing_value(s1); // in the lefttest_passing_value(std::move(s1)); // in the righttest_passing_value(sr); // in the lefttest_passing_value(std::move(sr)); // in the right// 可以看到无论是左值，还是左值引用，使用std::move之后都可以变成右值引用// 意外的情况就是const T&amp; 在使用std::move转化时的特殊情况 const T&amp; vs T&amp;&amp;c++11中引入了右值引用和move语义，初学者（比如我）很容易被这种特性吸引（move比copy快）, 两者其实是解决不同场景下的问题，T&amp;&amp; 的确提供了一种更为高效的传参方式, 让我们看下两者的细节和使用场景吧。 仅仅使用const T&amp;并不会发生copy 12345678void foo(const String&amp; s) &#123; std::cout &lt;&lt; s &lt;&lt; std::endl;&#125;int main() &#123; String s0(&quot;hello&quot;); foo(s0); // 不会发生复制&#125; const T&amp; 发生复制的情况是在函数体内用到T的local variable， 比如T local = t, 这时候会发生拷贝控制 仅仅使用T&amp;&amp;不会发生move 1234567void f2(String &amp;&amp;s2) &#123; std::cout &lt;&lt; s2 &lt;&lt; std::endl;&#125;int main() &#123; f2(String(&quot;hello&quot;));&#125; 从以上两种情况来看似乎传参的代价都很低，那么应该如何选择呢，主要还是根据语义来做选择，如果你的实参是个左值自然选择第一种，如果是右值那自然是后者，如果你确定需要第二种那么使用std::move也是可以的 结论 由于我在传给callback的string是从buffer中复制构造来的，而不是仅仅像stringpiece那样使用，所以使用右值引用更合适，使用者会放心大胆的使用这个string，move之类的更不在话下了 其他 可以考虑使用StringPiece类似的技术，不过我感觉StringPiece在这个场景下并不好 关于std::move的原理其中涉及到了引用折叠这些比较复杂的概念，所以没有深入介绍 在模板中使用T&amp;&amp; 和实参中的&amp;&amp;还是不一样的，模板中的T&amp;&amp; 在转发参数时要保证不丢失T的信息(T可能是引用) 所以有涉及到了完美转发的概念，std::forward可以解决这个问题","categories":[],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://skyitachi.github.io/tags/cpp/"}]},{"title":"浅谈 javascript 作用域","slug":"scope","date":"2017-04-23T16:00:00.000Z","updated":"2017-04-23T16:00:00.000Z","comments":true,"path":"2017/04/24/scope/","permalink":"https://skyitachi.github.io/2017/04/24/scope/","excerpt":"","text":"前言 本文将主要介绍javascript中作用域相关的问题，尽可能多的使用代码举例说明，尽量少涉及动态作用域相关 词法作用域(核心) javascript的作用域是词法作用域（静态作用域）, 不过像eval，with这些具有动态改变作用域的能力, 本文重点在于词法作用域 1234567891011121314151617181920212223242526272829303132333435363738let a = 1;function testLexicalScope() &#123; console.log(a); // 由于当前scope中a是由最外层定义的，所以此处的a只能访问到最外层的a&#125;function b() &#123; let a = 2; testLexicalScope();&#125;b();// 另一个例子let sameVar1 = 1;let sameVar2 = 1;function outerScope() &#123; let sameVar1 = 2; function innerScope() &#123; console.log(&quot;current scope: sameVar1 is &quot;, sameVar1); // 当前的scope中最近的sameVar1值是2 console.log(&quot;current scope: sameVar2 is &quot;, sameVar2); &#125; innerScope();&#125;outerScope();// current scope: sameVar1 is 2// current scope: sameVar2 is 1//另一个例子const f1 = function () &#123; console.log(outVar);&#125;;let outVar = 1;f1(); // 1 why 只有在函数声明的时候才会遵循lexical scope的规则, 如果是函数表达式则取决于调用的时机 不同类型的作用域(如何创建scope) 函数作用域 属于这个函数的全部变量都可以在整个函数的范围内使用及复用javascript 每个函数都会创建一个scope 12345678function fScope() &#123; var aStr = &quot;function&quot;; console.log(aStr);&#125;fScope();console.log(aStr); // ReferenceError: aStr is not defined 块级作用域({…}) 12345678var foo = true;&#123; // 这里是使用let，将foo绑定到了&#123;&#125;这个块作用域中 let foo = false; let bar = &quot;cannot seen&quot;; console.log(foo); // false&#125;console.log(foo); // trueconsole.log(bar); // ReferenceError var 函数作用域中的var仍然遵循函数作用域相关的 var中没有块级作用域 1234567var foo = true;&#123; var foo = false; var bar = true;&#125;console.log(foo); // falseconsole.log(bar); // bar 变量提升 变量和函数的所有声明多会在任何代码被执行前首先被处理（编译器找到这些变量与合适的作用域关联） 1234567function hoisting() &#123; console.log(a); var a = 1; console.log(a);&#125;hoisting(); 又是let 123456function hoisting() &#123; console.log(a); // 第一个let之上的区域叫做`temporal dead zone` let a = 1; console.log(a);&#125;hoisting(); // ReferenceError 函数声明的优先级会高于变量声明 1234567foo(); // in the functionvar foo = 1;function foo() &#123; console.log(&quot;in the function&quot;);&#125; 总结 关于块级作用域, 可用try{} catch(err) {&#x2F;这里是块级作用域&#x2F;}模拟，更多参考:《你不知道的javascript》上卷中3.4.2节 使用let，const是最佳实践 需要区分函数声明和函数表达式 尽量不要写有提升的代码（声明尽量提前）","categories":[],"tags":[{"name":"javascript","slug":"javascript","permalink":"https://skyitachi.github.io/tags/javascript/"}]}],"categories":[],"tags":[{"name":"ES, Lucene, elasticsearch","slug":"ES-Lucene-elasticsearch","permalink":"https://skyitachi.github.io/tags/ES-Lucene-elasticsearch/"},{"name":"golang slice","slug":"golang-slice","permalink":"https://skyitachi.github.io/tags/golang-slice/"},{"name":"algorithm","slug":"algorithm","permalink":"https://skyitachi.github.io/tags/algorithm/"},{"name":"dubbo, go, protobuf","slug":"dubbo-go-protobuf","permalink":"https://skyitachi.github.io/tags/dubbo-go-protobuf/"},{"name":"cpp","slug":"cpp","permalink":"https://skyitachi.github.io/tags/cpp/"},{"name":"javascript","slug":"javascript","permalink":"https://skyitachi.github.io/tags/javascript/"}]}