{"meta":{"title":"skyitachi's blog","subtitle":null,"description":"一定要有输出","author":"skyitachi","url":"https://skyitachi.github.io","root":"/"},"pages":[],"posts":[{"title":"ann-benchmarks中hnsw简单解读","slug":"hnswlib和faiss_hnsw的ann-benchmarks结果解读","date":"2024-07-22T16:00:00.000Z","updated":"2024-07-22T16:00:00.000Z","comments":true,"path":"2024/07/23/hnswlib和faiss_hnsw的ann-benchmarks结果解读/","permalink":"https://skyitachi.github.io/2024/07/23/hnswlib%E5%92%8Cfaiss_hnsw%E7%9A%84ann-benchmarks%E7%BB%93%E6%9E%9C%E8%A7%A3%E8%AF%BB/","excerpt":"","text":"hnswlib和faiss_hnsw在ann-benchmark中的参数解读benchmark链接只需要关注hnswlib和hnsw(faiss) 即可 声明 数据集: sift-128-euclidean数据集(向量的维度是128) k-nn的k是10 hnswlib和faiss_hnsw的benchmark都是基于单线程的 benchmark的细节点说明 hnswlib中有相同图例的点, eg：Parameters: hnswlib (&#123;&#39;M&#39;: 12, &#39;efConstruction&#39;: 500&#125;) 这样得点标记了好几个，但是QPS和Recall都不相同,原因在于hnswlib的benchmark配置中有query-args参数 1234567891011121314151617181920// ann_benchmarks/algorithms/hnswlib/config.ymlfloat: any: - base_args: [&#x27;@metric&#x27;] constructor: HnswLib disabled: false docker_tag: ann-benchmarks-hnswlib module: ann_benchmarks.algorithms.hnswlib name: hnswlib run_groups: M-12: arg_groups: [&#123;M: 12, efConstruction: 500&#125;] args: &#123;&#125; query_args: [[10, 20, 40, 80, 120, 200, 400, 600, 800]] ...// query_args 对应了 hnswlib/module.py中的set_query_arguments函数的参数 def set_query_arguments(self, ef): self.p.set_ef(ef) hnswlib中set_ef和faiss_hnsw中设置efSearch的效果是一样的, faiss中的图例就标注了efSearch(ef) ,&quot;faiss (&#123;&#39;M&#39;: 12, &#39;efConstruction&#39;: 500&#125;, ef: 80) efSearch不影响build，所以在Recall&#x2F;Build time的图上hnswlib就没有”重复”的点了 hnswlib和faiss_hnsw的性能表现主要看recall和build的表现 ann-benchmark中的表现参考ann-benchmark的论文，他们运行的硬件环境是: Amazon EC2 c5.4xlarge instances that are equipped with Intel Xeon Platinum 8124M CPU (16 cores available, 3.00 GHz, 25.0MB Cache) and 32GB of RAM running Amazon Linux. ann-benchmarks网站上的benchmark如下: 说明: 整体QPS随着recall的上升成指数级的下降 (两者都是) 相同召回率的情况下，hnswlib的QPS要高一点, 由于faiss标注了ef(efSearch)但是hnswlib没有标注，所以比较起来不太直观，后面我在本地自己跑的时候给hnswlib带上了ef参数，这样就更加直观了 说明: 1. Build Index Time也是hnswlib占优 本地的表现硬件环境: AMD Ryzen 5 3600 (3.6G Hz), 6 core 12 threads, 32GB of RAM running Ubuntu 24.04 这里我修改了ann-benchmarks中hnswlib的环境和在efConstruction&#x3D;200和500的情况下比较hnswlib的表现 123456789// ann_benchmarks/algorithms/hnswlib/config.ymlFROM ann-benchmarks# RUN apt-get install -y python-setuptools python-pipRUN pip3 install pybind11 numpy setuptools hnswlib==0.8.0# RUN cd hnsw/python_bindings; python3 setup.py installRUN python3 -c &#x27;import hnswlib&#x27; Recall &amp; QPS 表现关于recall 我们更需要关注是否通过参数配置到足够高的精度，我这里以0.99的recall作为基础，主要比较在0.99以上的召回率条件下(qps &gt; 2000)，两种算法实现的qps及其对应的参数 algorithm parameters k-nn(recall) qps build(s) indexsize(kb) faiss_hnsw faiss ({‘M’: 24, ‘efConstruction’: 500}, ef: 80) 0.99031 2561.923162412995 1458.773098230362 794864.0 faiss_hnsw faiss ({‘M’: 16, ‘efConstruction’: 500}, ef: 120) 0.99347 2194.419076982479 1285.849939107895 732492.0 faiss_hnsw faiss ({‘M’: 36, ‘efConstruction’: 500}, ef: 80) 0.99314 2191.7604350595634 1585.1033165454865 888936.0 faiss_hnsw faiss ({‘M’: 48, ‘efConstruction’: 500}, ef: 80) 0.99411 2077.6779248107487 1667.5446255207062 982148.0 hnswlib hnswlib ({‘M’: 64, ‘efConstruction’: 200}, ef: 80) 0.9901500000000001 3731.2651844102425 496.65849924087524 1150800.0 hnswlib hnswlib ({‘M’: 96, ‘efConstruction’: 200}, ef: 80) 0.9902599999999999 3616.44180507205 513.7249546051025 1400632.0 hnswlib hnswlib ({‘M’: 36, ‘efConstruction’: 500}, ef: 80) 0.99308 3571.6658501707066 1156.385510444641 931660.0 hnswlib hnswlib ({‘M’: 24, ‘efConstruction’: 200}, ef: 120) 0.9939 3314.9200264352426 426.75320744514465 838564.0 hnswlib hnswlib ({‘M’: 48, ‘efConstruction’: 500}, ef: 80) 0.99433 3290.7135482210724 1246.9214706420898 1026148.0 hnswlib hnswlib ({‘M’: 64, ‘efConstruction’: 500}, ef: 80) 0.9946999999999999 3153.6867226554614 1276.8294219970703 1146332.0 hnswlib hnswlib ({‘M’: 24, ‘efConstruction’: 500}, ef: 120) 0.9955999999999999 3139.927141602247 1008.0483357906342 838676.0 hnswlib hnswlib ({‘M’: 12, ‘efConstruction’: 200}, ef: 200) 0.9920199999999999 3100.2119285498034 313.95580410957336 745664.0 hnswlib hnswlib ({‘M’: 12, ‘efConstruction’: 500}, ef: 200) 0.99271 3040.3355289720653 709.9178235530853 745132.0 hnswlib hnswlib ({‘M’: 96, ‘efConstruction’: 500}, ef: 80) 0.9949 3036.296166689699 1317.8283751010895 1400940.0 hnswlib hnswlib ({‘M’: 36, ‘efConstruction’: 200}, ef: 120) 0.99544 2873.9128879689624 466.08784890174866 931436.0 hnswlib hnswlib ({‘M’: 48, ‘efConstruction’: 200}, ef: 120) 0.9956799999999999 2690.4460742892884 482.9417383670807 1025096.0 hnswlib hnswlib ({‘M’: 64, ‘efConstruction’: 200}, ef: 120) 0.99576 2671.663602183599 496.65849924087524 1150800.0 hnswlib hnswlib ({‘M’: 36, ‘efConstruction’: 500}, ef: 120) 0.99753 2612.247989122775 1156.385510444641 931660.0 hnswlib hnswlib ({‘M’: 96, ‘efConstruction’: 200}, ef: 120) 0.99588 2581.161300550079 513.7249546051025 1400632.0 hnswlib hnswlib ({‘M’: 16, ‘efConstruction’: 200}, ef: 200) 0.9962 2565.1980331237614 364.242990732193 778360.0 hnswlib hnswlib ({‘M’: 48, ‘efConstruction’: 500}, ef: 120) 0.9979100000000001 2394.6802442922076 1246.9214706420898 1026148.0 hnswlib hnswlib ({‘M’: 64, ‘efConstruction’: 500}, ef: 120) 0.9980800000000001 2282.691070497442 1276.8294219970703 1146332.0 hnswlib hnswlib ({‘M’: 96, ‘efConstruction’: 500}, ef: 120) 0.99821 2188.4360442789643 1317.8283751010895 1400940.0 hnswlib hnswlib ({‘M’: 24, ‘efConstruction’: 200}, ef: 200) 0.99818 2166.896152958348 426.75320744514465 838564.0 hnswlib hnswlib ({‘M’: 8, ‘efConstruction’: 200}, ef: 400) 0.99244 2138.951169866413 256.2939279079437 715140.0 hnswlib hnswlib ({‘M’: 8, ‘efConstruction’: 500}, ef: 400) 0.9936 2124.6338197635687 588.7308986186981 715372.0 hnswlib hnswlib ({‘M’: 24, ‘efConstruction’: 500}, ef: 200) 0.9989100000000001 2017.995520316913 1008.0483357906342 838676.0 Build Index Time algorithm parameters indexsize build hnswlib hnswlib ({‘M’: 8, ‘efConstruction’: 200}, ef: 400) 715140.0 256.2939279079437 hnswlib hnswlib ({‘M’: 12, ‘efConstruction’: 200}, ef: 200) 745664.0 313.95580410957336 hnswlib hnswlib ({‘M’: 16, ‘efConstruction’: 200}, ef: 200) 778360.0 364.242990732193 hnswlib hnswlib ({‘M’: 24, ‘efConstruction’: 200}, ef: 120) 838564.0 426.75320744514465 hnswlib hnswlib ({‘M’: 36, ‘efConstruction’: 200}, ef: 120) 931436.0 466.08784890174866 hnswlib hnswlib ({‘M’: 48, ‘efConstruction’: 200}, ef: 120) 1025096.0 482.9417383670807 hnswlib hnswlib ({‘M’: 64, ‘efConstruction’: 200}, ef: 120) 1150800.0 496.65849924087524 hnswlib hnswlib ({‘M’: 96, ‘efConstruction’: 200}, ef: 80) 1400632.0 513.7249546051025 hnswlib hnswlib ({‘M’: 8, ‘efConstruction’: 500}, ef: 400) 715372.0 588.7308986186981 hnswlib hnswlib ({‘M’: 12, ‘efConstruction’: 500}, ef: 200) 745132.0 709.9178235530853 hnswlib hnswlib ({‘M’: 24, ‘efConstruction’: 500}, ef: 120) 838676.0 1008.0483357906342 hnswlib hnswlib ({‘M’: 36, ‘efConstruction’: 500}, ef: 120) 931660.0 1156.385510444641 hnswlib hnswlib ({‘M’: 48, ‘efConstruction’: 500}, ef: 120) 1026148.0 1246.9214706420898 hnswlib hnswlib ({‘M’: 64, ‘efConstruction’: 500}, ef: 120) 1146332.0 1276.8294219970703 faiss_hnsw faiss ({‘M’: 16, ‘efConstruction’: 500}, ef: 120) 732492.0 1285.849939107895 hnswlib hnswlib ({‘M’: 96, ‘efConstruction’: 500}, ef: 120) 1400940.0 1317.8283751010895 faiss_hnsw faiss ({‘M’: 24, ‘efConstruction’: 500}, ef: 80) 794864.0 1458.773098230362 faiss_hnsw faiss ({‘M’: 36, ‘efConstruction’: 500}, ef: 80) 888936.0 1585.1033165454865 faiss_hnsw faiss ({‘M’: 48, ‘efConstruction’: 500}, ef: 80) 982148.0 1667.5446255207062 说明1.efConstruction越小，build 耗费时间越小，牺牲的精确性可以通过加大ef来弥补, 要想获取最佳性能需要对M，efConstruction, ef这三个参数进行平衡2.indexsize 只和M有关系3.整体而言，hnswlib的性能仍然要比faiss的hnsw的要好一点, 两者差距不大4.efConstruction&#x3D;200的情况下通过适当调大ef也能实现较高的召回率，也不会带来性能损失，但是对Build Index Time 会有较大的提升 其他细节指标解读 ann-benchmarks中通过python data_export.py可以得出详细的指标数据, 其中有两列epsilon, largeepsilon这里其实对应得是在算recall的时候，允许的距离误差大小(使用euclidean距离，就是向量召回的点和实际的knn的点距离误差), epsilon 是0.01， largeepsilon, 允许的误差越大，对应的recall 就越高, 论文中的实际公式如下: indexsize在graph base的算法中都挺大的，不过整体上hnswlib的更小一点 总结 这里列举都是在特定数据集下的表现，事实上不同数据集下不同类型的算法表现不尽相同，hnswlib不是在任何情况下的表现都由于faiss_hnsw， 那在实际的生产环境中，还是需要对不同的算法进行benchmark，从而得出更好的参数和选出更好的算法 ann-benchmarks的论文指出虽然graph-based的算法在rand-euclidean的数据集下性能还不如faiss-ivf，但是在实际的数据集上，往往会有所谓的global structure出现，graph based的算法一般都是更好的选择，graph based中的hnsw也是更好的选择 ann-benchmarks也指出如果使用GPU的话，graph based的算法不如ivf这种简单的算法","categories":[],"tags":[{"name":"algorithm hnsw 向量数据库 faiss hnswlib","slug":"algorithm-hnsw-向量数据库-faiss-hnswlib","permalink":"https://skyitachi.github.io/tags/algorithm-hnsw-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93-faiss-hnswlib/"}]},{"title":"HNSW算法原理及其实现","slug":"HNSW算法原理及其实现","date":"2024-07-21T16:00:00.000Z","updated":"2024-07-21T16:00:00.000Z","comments":true,"path":"2024/07/22/HNSW算法原理及其实现/","permalink":"https://skyitachi.github.io/2024/07/22/HNSW%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"主要内容 介绍HNSW的算法原理 介绍hnswlib和faiss中的实现，以及他们之间的区别 介绍HNSW中每个参数的实际影响 HNSW的算法原理概述 HNSW的算法大致原理很像skplist，区别在于hnsw每层维护的是节点直接的链接（links）,每一层都是graph的结构，相同点就是每下一层的节点数更多,维护的图也越大，到了0层维护了所有节点的链接信息 无论是插入还是查找，都是从上往下找enter point（当前层和插入或者查询点最接近的点）,到了下一层时候，通过在enter point的链接的点中早出指定数量的候选集，并选出和目标点最接近的指定数量的点，建立连接 插入算法还需要维护当前的enter point 具体算法论文中有提到一些最佳参数设置，mL &#x3D; 1&#x2F;ln(M), Mmax &#x3D; M, Mmax0 &#x3D; M * 2 可以直接带入算法中的参数，减少未知量，看起来会清晰一点，其中hnswlib的实现就是按照这组参数来的 SEARCH-LAYER算法SEARCH-LAYER(q, ep, ef, lc) Input: query element q, enter points ep, number of nearest to q elements to return ef, layer number lc Output: ef closest neighbors to q 123456789101112131415161718192021v ← ep // set of visited elementsC ← ep // set of candidatesW ← ep // dynamic list of found nearest neighborswhile │C│ &gt; 0 c ← extract nearest element from C to q f ← get furthest element from W to q if distance(c, q) &gt; distance(f, q) break // all elements in W are evaluated for each e ∈ neighbourhood(c) at layer lc // update C and W if e ∉ v v ← v ⋃ e f ← get furthest element from W to q if distance(e, q) &lt; distance(f, q) or │W│ &lt; ef C ← C ⋃ e W ← W ⋃ e if │W│ &gt; ef remove furthest element from W to qreturn W 说明 ep可以是由多个点组成的集合，也可以是单个点 插入算法INSERT(hnsw, q, M, Mmax, efConstruction, mL) Input: multilayer graph hnsw, new element q, number of established connections M, maximum number of connections for each element per layer Mmax, size of the dynamic candidate list efConstruction, normalization factor for level generation mL Output: update hnsw inserting element q 1234567891011121314151617181920212223W ← ∅ // list for the currently found nearest elementsep ← get enter point for hnswL ← level of ep // top layer for hnswl ← ⌊-ln(unif(0..1))∙mL⌋ // new element’s levelfor lc ← L … l+1 W ← SEARCH-LAYER(q, ep, ef=1, lc) ep ← get the nearest element from W to qfor lc ← min(L, l) … 0 W ← SEARCH-LAYER(q, ep, efConstruction, lc) neighbors ← SELECT-NEIGHBORS(q, W, M, lc) // alg. 3 or alg. 4 add bidirectionall connectionts from neighbors to q at layer lc for each e ∈ neighbors // shrink connections if needed eConn ← neighbourhood(e) at layer lc if │eConn│ &gt; Mmax // shrink connections of e if lc = 0 then Mmax = Mmax0 eNewConn ← SELECT-NEIGHBORS(e, eConn, Mmax, lc) // alg. 3 or alg. 4 set neighbourhood(e) at layer lc to eNewConn ep ← Wif l &gt; L set enter point for hnsw to q entry point的更新 新插入的节点最终会变为全局的enter pointer level0会维护2*M的链接 搜索算法K-NN-SEARCH(hnsw, q, K, ef) Input: multilayer graph hnsw, query element q, number of nearest neighbors to return K, size of the dynamic candidate list ef Output: K nearest elements to q 123456789W ← ∅ // set for the current nearest elementsep ← get enter point for hnswL ← level of ep // top layer for hnswfor lc ← L … 1 W ← SEARCH-LAYER(q, ep, ef=1, lc) ep ← get nearest element from W to qW ← SEARCH-LAYER(q, ep, ef, lc =0)return K nearest elements from W to q 说明 搜索过程从L-&gt;1 层每层只搜和query最近的enter point, 这就要求数据集是要有一定结构的，这样才能保证在最后一层搜索的时候质量不至于太差，如果是随机的数据集可能结果会不太好 efSearch要大于K才行(faiss里会保证efSearch最少是k) SELECT-NEIGHBORS 算法简单算法123456SELECT-NEIGHBORS-SIMPLE(q, C, M)Input: base element q, candidate elements C, number of neighbors to return MOutput: M nearest elements to qreturn M nearest elements from C to q// 实际的实现就是一个优先权队列 启发式方法SELECT-NEIGHBORS-HEURISTIC(q, C, M, lc, extendCandidates, keepPrunedConnections) Input: base element q, candidate elements C, number of neighbors to return M, layer number lc, flag indicating whether or not to extendcandidate list extendCandidates, flag indicating whether or not to add discarded elements keepPrunedConnections Output: M elements selected by the heuristic 12345678910111213141516171819202122R ← ∅W ← C // working queue for the candidatesif extendCandidates // extend candidates by their neighbors for each e ∈ C for each eadj ∈ neighbourhood(e) at layer lc if eadj ∉ W W ← W ⋃ eadjWd ← ∅ // queue for the discarded candidateswhile │W│ &gt; 0 and │R│&lt; M e ← extract nearest element from W to q if e is closer to q compared to any element from R R ← R ⋃ e else Wd ← Wd ⋃ eif keepPrunedConnections // add some of the discarded // connections from Wd while │Wd│&gt; 0 and │R│&lt; M R ← R ⋃ extract nearest element from Wd to qreturn R 说明 第一种方法只从candidates选择，第二种方法从candidates里的邻接的点里选择（选择范围更大, 可能受数据集的影响较小） hnswlib和faiss_hnsw都相当于用了第一种方法 启发式方法适合中维数据和多clustering的数据( mid-dimensional data and for the case of highly clustered data) HNSW每个参数实际的影响 dim: 数据维度，dim 越大计算量越大 max_elements: 数据总量 M: 每个向量的最大链接数, M越大占用的内存越大, 构建和搜索也是越慢（精度更高） efConstruction: 每个向量构建或者搜索时的候选集大小，efConstruction越大，构建和搜索速度越慢 (不会影响内存消耗) M 应该如何选择 论文中指出A reasonable range of M is from 5 to 48 efConstruction efConstruction 对speed&#x2F;index quality有显著影响 论文中指出10M的sift dataset，用efConstruction&#x3D;100就能达到不错的召回率(0.95), 适用多线程并发构建的话速度也不错 进一步提升efConstruction带来的收益并不明显，反而会较大影响构建速度 efSearch 搜索时候用到ef值，hnswlib和faiss_hnsw都可以单独设置 合适的efSearch能保证recall efSearch也不是越高越好，边际效应越来越小，也会影响到搜索速度 总结 关于详细的性能数据可以参考论文 测试性能的时候关键指标是 Distance Computations, Query Time 可以使用PQ（乘积量化）的方式优化memory","categories":[],"tags":[{"name":"algorithm hnsw 向量数据库","slug":"algorithm-hnsw-向量数据库","permalink":"https://skyitachi.github.io/tags/algorithm-hnsw-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"ES和Lucene之间的CRUD操作映射","slug":"ES和Lucene之间的CRUD操作映射","date":"2024-05-10T16:00:00.000Z","updated":"2024-07-06T16:00:00.000Z","comments":true,"path":"2024/05/11/ES和Lucene之间的CRUD操作映射/","permalink":"https://skyitachi.github.io/2024/05/11/ES%E5%92%8CLucene%E4%B9%8B%E9%97%B4%E7%9A%84CRUD%E6%93%8D%E4%BD%9C%E6%98%A0%E5%B0%84/","excerpt":"","text":"前言在ES中我们经常使用的数据格式json，ES也支持常见的CRUD操作，这里我们主要介绍写入相关的操作（创建，更新，删除），ES的底层存储引擎是Lucene，Lucene也有相关创建更新删除的操作，但是Lucene是没有显示的根据主键更新文档的api的，本文主要介绍的是在ES有_id的情况下，ES是如何基于Lucene实现增删改的操作的，其中的数据模型又是如何映射的. ps: 本文不考虑ES中的数据类型到Lucene中的数据类型的映射（Field），所有的代码片段都是基于以下给定的类型映射 Name ES type Lucene Field item_id keyword StringField name keyword StringField color keyword StringField lucene 如何基于id（主键）部分更新文档 (基于lucene 9.7.0)12345 &lt;dependency&gt; &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt; &lt;artifactId&gt;lucene-core&lt;/artifactId&gt; &lt;version&gt;9.7.0&lt;/version&gt;&lt;/dependency&gt; 1. 创建文档123456789101112131415161718public static void createDocuments(IndexWriter indexWriter) throws IOException &#123; Document doc1 = new Document(); doc1.add(new StringField(&quot;item_id&quot;, &quot;1&quot;, Field.Store.YES )); doc1.add(new StringField(&quot;name&quot;, &quot;item1&quot;, Field.Store.YES)); doc1.add(new StringField(&quot;color&quot;, &quot;red&quot;, Field.Store.YES)); Document doc2 = new Document(); doc2.add(new StringField(&quot;item_id&quot;, &quot;2&quot;, Field.Store.YES)); doc2.add(new StringField(&quot;name&quot;, &quot;item2&quot;, Field.Store.YES)); doc2.add(new StringField(&quot;color&quot;, &quot;blue&quot;, Field.Store.YES)); indexWriter.addDocument(doc1); indexWriter.addDocument(doc2); indexWriter.commit(); indexWriter.flush();&#125; 2. 读取文档验证写入1234567891011121314public static void getDocumentById(IndexReader reader, IndexSearcher searcher, String itemId) throws IOException &#123; Query query = new TermQuery(new Term(&quot;item_id&quot;, itemId)); TopDocs topdocs = searcher.search(query, 10); assert topdocs.totalHits.value == 1; for (ScoreDoc doc: topdocs.scoreDocs) &#123; int docId = doc.doc; Document fullDoc = getDocumentByDocId(reader, docId); fullDoc.getFields().forEach(field -&gt; &#123; System.out.println(&quot; &quot; + field.name() + &quot;: &quot; + field.stringValue()); &#125;); &#125;&#125; 123456789// item_id = &quot;1&quot;getDocumentById(reader, searcher, &quot;1&quot;);// item_id: 1// name: item1// color: redgetDocumentById(reader, searcher, &quot;2&quot;);// item_id: 2// name: item2// color: blue 3. 部分更新文档123456789public static void partialUpdateDocumentNameByItemId(IndexWriter writer, String itemId, String newName) throws IOException &#123; Document doc = new Document(); doc.add(new StringField(&quot;name&quot;, newName, Field.Store.YES)); // important: 这个作为主键的Term一定要带上 doc.add(new StringField(&quot;item_id&quot;, itemId, Field.Store.YES)); Term mainTerm = new Term(&quot;item_id&quot;, itemId); writer.updateDocument(mainTerm, doc);&#125; 4. 验证更新文档123456789101112131415161718partialUpdateDocumentNameByItemId(indexWriter, &quot;1&quot;, &quot;item1_updated&quot;);partialUpdateDocumentNameByItemId(indexWriter, &quot;2&quot;, &quot;item2_updated&quot;);indexWriter.commit();indexWriter.flush();indexReader = DirectoryReader.open(readDirectory);indexSearcher = new IndexSearcher(indexReader);getDocumentById(indexSearcher, &quot;1&quot;);indexReader = DirectoryReader.open(readDirectory);indexSearcher = new IndexSearcher(indexReader);getDocumentById(indexSearcher, &quot;2&quot;);//// name: item1_updated// item_id: 1// name: item2_updated// item_id: 2 结论： 由于在partialUpdateDocumentNameByItemId 中只写了item_id和name属性（符合update的直觉），但是可以看出Lucene把updateDocument中的doc对象当成了最新且完整的mainTerm对应的doc，这就导致了虽然我们目的是部分更新，但是会丢失没有写入（没有变化）的那些属性，这个例子也可以看出Lucene本质上是用新文档覆盖旧文档的形式，用一个可以代表主键的Term做关联，来实现部分更新字段的目的，这个和一般RDBMS的存储模型有点区别. 5. 完全更新所有字段（不变的field也要加入将要更新的document中）123456789public static void fullUpdateDocumentNameByItemId(IndexWriter writer, String itemId, String newName, String oldColor) throws IOException &#123; Document doc = new Document(); doc.add(new StringField(&quot;name&quot;, newName, Field.Store.YES)); doc.add(new StringField(&quot;item_id&quot;, itemId, Field.Store.YES)); doc.add(new StringField(&quot;color&quot;, oldColor, Field.Store.YES)); Term mainTerm = new Term(&quot;item_id&quot;, itemId); writer.updateDocument(mainTerm, doc);&#125; 6. 验证完全更新123456789101112131415161718192021fullUpdateDocumentNameByItemId(indexWriter, &quot;1&quot;, &quot;item1_updated&quot;, &quot;red&quot;);fullUpdateDocumentNameByItemId(indexWriter, &quot;2&quot;, &quot;item2_updated&quot;, &quot;blue&quot;);indexWriter.commit();indexWriter.flush();indexReader = DirectoryReader.open(readDirectory);indexSearcher = new IndexSearcher(indexReader);getDocumentById(indexSearcher, &quot;1&quot;);indexReader = DirectoryReader.open(readDirectory);indexSearcher = new IndexSearcher(indexReader);getDocumentById(indexSearcher, &quot;2&quot;);// output// name: item1_updated// item_id: 1// color: red// name: item2_updated// item_id: 2// color: blue 7. 删除文档1234public static void deleteDocument(IndexWriter writer, String itemId) throws IOException &#123; Term mainTerm = new Term(&quot;item_id&quot;, itemId); writer.deleteDocuments(mainTerm);&#125; 8. 验证删除文档12345getDocumentById(indexSearcher, &quot;1&quot;);getDocumentById(indexSearcher, &quot;2&quot;);// cannot found 1// cannot found 2 结论： 必须将原始文档的所有字段全部获取到再用updateDocument的方式更新，才能实现我们预期中部分更新字段的目的，可以看到成本还是比较高的 由于Lucene的这种机制也导致了，ES的CRUD模型中需要实现一些额外的机制才能使用到Lucene的能力 ES中的操作ES mapping12345678910111213141516PUT /my_index&#123; &quot;mappings&quot;: &#123; &quot;properties&quot;: &#123; &quot;item_id&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;name&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125;, &quot;color&quot;: &#123; &quot;type&quot;: &quot;keyword&quot; &#125; &#125; &#125;&#125; 1. 创建文档12345678910111213PUT my_index/_doc/1&#123; &quot;item_id&quot;: &quot;1&quot;, &quot;name&quot;:&quot;item1&quot;, &quot;color&quot;: &quot;red&quot;&#125;PUT my_index/_doc/2&#123; &quot;item_id&quot;: &quot;2&quot;, &quot;name&quot;:&quot;item2&quot;, &quot;color&quot;: &quot;blue&quot;&#125; 2. 获取文档123456789101112131415161718192021222324252627GET my_index/_search// output&#123; ... &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;my_index&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;item_id&quot;: &quot;1&quot;, &quot;name&quot;: &quot;item1&quot;, &quot;color&quot;: &quot;red&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;my_index&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;item_id&quot;: &quot;2&quot;, &quot;name&quot;: &quot;item2&quot;, &quot;color&quot;: &quot;blue&quot; &#125; &#125; ]&#125; 3.部分更新12345678910111213POST my_index/_update/1&#123; &quot;doc&quot;: &#123; &quot;name&quot;: &quot;item1_updated&quot; &#125;&#125;POST my_index/_update/2&#123; &quot;doc&quot;: &#123; &quot;name&quot;: &quot;item2_updated&quot; &#125;&#125; 4.获取部分更新后的文档123456789101112131415161718192021222324252627GET my_index/_search// output&#123; ... &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;my_index&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;item_id&quot;: &quot;1&quot;, &quot;name&quot;: &quot;item1_updated&quot;, &quot;color&quot;: &quot;red&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;my_index&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;item_id&quot;: &quot;2&quot;, &quot;name&quot;: &quot;item2_updated&quot;, &quot;color&quot;: &quot;blue&quot; &#125; &#125; ]&#125; 说明: 可以看ES中部分更新是可以正常的工作的, 原因就在于ES在处理update的时候会自动拉取原始文档的所有字段和新的更新的字段组合成一份完整的新的全量字段的文档，再去更新Lucene 5. 完整更新所有字段1234567891011121314151617// 方式一POST my_index/_update/1&#123; &quot;doc&quot;: &#123; &quot;name&quot;: &quot;item1_updated&quot;, &quot;item_id&quot;: &quot;1&quot;, &quot;color&quot;: &quot;red&quot; &#125;&#125;// 方式二PUT my_index/_doc/1&#123; &quot;item_id&quot;: &quot;1&quot;, &quot;name&quot;:&quot;item1_update_by_put&quot;, &quot;color&quot;: &quot;red&quot;&#125; 6. 验证完全更新123456789101112131415161718192021222324252627GET my_index/_search// output&#123; ... &quot;hits&quot;: [ &#123; &quot;_index&quot;: &quot;my_index&quot;, &quot;_id&quot;: &quot;1&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;item_id&quot;: &quot;1&quot;, &quot;name&quot;: &quot;item1_update_by_put&quot;, &quot;color&quot;: &quot;red&quot; &#125; &#125;, &#123; &quot;_index&quot;: &quot;my_index&quot;, &quot;_id&quot;: &quot;2&quot;, &quot;_score&quot;: 1, &quot;_source&quot;: &#123; &quot;item_id&quot;: &quot;2&quot;, &quot;name&quot;: &quot;item2_updated&quot;, &quot;color&quot;: &quot;blue&quot; &#125; &#125; ]&#125; 7. 删除文档12DELETE my_index/_doc/1DELETE my_index/_doc/2 8. 验证删除文档12345678GET my_index/_search// output&#123; ... &quot;hits&quot;: []&#125; ES如何在Lucene的基础上实现基于主键(_id)的删改 ES 使用_id的内部字段作为文档的主键，这个_id可以用户指定，上面的例子中item_id就是对应了_id，Lucene中没有主键的概念，所以需要使用_id 作为一个独特的Term的维持文档的唯一性, 后续的更新, 删除也是和_id对应的Term绑定. Lucene的创建操作不具备幂等性（addDocument）指定了Term之后，这个Term下可以关联N个document，不具备唯一性. ES 在部分字段的更新中，自己封装了一层获取原始文档的操作，之后使用update的方式更新Lucene. ES 在删除文档操作中，使用_id对应的Term 去调用Lucene的API. ES 在创建文档操作中，PUT 相同_id的文档 同样能保持唯一性, 通常情况下ES也是用Lucene update的方式实现创建的请求. 总结 Lucene整体是一个Append Only的存储引擎，且没有主键的概念. ES 本身封装了一系列的操作使得整个CRUD操作更加方便使用，这也不可避免的带了一些额外的开销，通过理解这些操作的底层原理，有助于我们做出一些最佳实践的选择.","categories":[],"tags":[{"name":"ES, Lucene, elasticsearch","slug":"ES-Lucene-elasticsearch","permalink":"https://skyitachi.github.io/tags/ES-Lucene-elasticsearch/"}]},{"title":"Golang 中[]byte, string和[]rune的相互转化的底层原理和剖析","slug":"golang_slice","date":"2021-02-21T02:15:38.000Z","updated":"2021-02-21T02:15:38.000Z","comments":true,"path":"2021/02/21/golang_slice/","permalink":"https://skyitachi.github.io/2021/02/21/golang_slice/","excerpt":"","text":"Golang 中[]byte, string和[]rune的相互转化的底层原理和剖析在golang中有些场景经常会用到[]byte和string的相互转化，尤其是在使用json.Marshal和json.Unmarshal的时候，经常会遇到需要这种转化。 本文主要说明以下内容： 几种类型相互转化的方法和性能分析 这些类型的底层存储 代码gist 相互转化[]byte和string的相互转化string -&gt; []byte1234567891011121314151617181920212223242526func BenchmarkStringToByteSlice(b *testing.B) &#123; s := genString(10000) b.ReportAllocs() for i := 0; i &lt; b.N; i++ &#123; bs := []byte(s) if len(bs) != len(s) &#123; b.Error(&quot;error&quot;) &#125; &#125;&#125;func BenchmarkStringToByteSliceUnsafe(b *testing.B) &#123; s := genString(10000) b.ReportAllocs() for i := 0; i &lt; b.N; i++ &#123; l := len(s) bs := *(*[]byte)(unsafe.Pointer(&amp;reflect.SliceHeader&#123; Data: (*(*reflect.StringHeader)(unsafe.Pointer(&amp;s))).Data, Len: l, Cap: l, &#125;)) if len(bs) != len(s) &#123; b.Error(&quot;error&quot;) &#125; &#125;&#125; 第一种使用[]byte这种直接转化，也是我们常用的方式，第二种是使用unsafe的方式。这两种区别就在于一个是重新分配了内存，另一个是复用了原来的内存。 benchmark的结果也验证了这一点 12345678910go test -run=BenchmarkStringToByteSlice -bench=StringToByteSlice# go-demo.testgoos: darwingoarch: amd64pkg: go-demoBenchmarkStringToByteSlice-12 1164224 964 ns/op 10285 B/op 1 allocs/opBenchmarkStringToByteSliceUnsafe-12 1000000000 0.380 ns/op 0 B/op 0 allocs/opPASSok go-demo 2.089s []byte -&gt; string12345678910111213141516171819202122func BenchmarkSliceByteToString(b *testing.B) &#123; bs := genSliceByte(100) b.ReportAllocs() for i := 0; i &lt; b.N; i++ &#123; s := string(bs) if len(s) != len(bs) &#123; b.Error(&quot;error&quot;) &#125; &#125;&#125;func BenchmarkSliceByteToStringUnsafe(b *testing.B) &#123; bs := genSliceByte(100) b.ReportAllocs() for i := 0; i &lt; b.N; i++ &#123; s := *(*string)(unsafe.Pointer(&amp;bs)) if len(s) != len(bs) &#123; b.Log(&quot;slice: &quot;, len(bs), &quot; string: &quot;, len(s)) b.Error(&quot;error: &quot;) &#125; &#125;&#125; benchmark 结果 12345678910go test -run=BenchmarkSliceByteToString -bench=SliceByteToString# go-demo.testgoos: darwingoarch: amd64pkg: go-demoBenchmarkSliceByteToString-12 35913873 32.4 ns/op 112 B/op 1 allocs/opBenchmarkSliceByteToStringUnsafe-12 1000000000 0.253 ns/op 0 B/op 0 allocs/opPASSok go-demo 3.796s string和[]rune的相互转化string和rune的相互转化其实和上面类似，主要是[]rune对应的[]byte数组长度需要计算下，这里就只贴一个[]rune到string的转化了 123456789101112131415161718func BenchmarkSliceRuneToStringUnsafe(b *testing.B) &#123; bs := genSliceRune(100) s1 := string(bs) b.ReportAllocs() for i := 0; i &lt; b.N; i++ &#123; var l int for _, r := range bs &#123; l += utf8.RuneLen(r) &#125; s := *(*string)(unsafe.Pointer(&amp;reflect.StringHeader&#123; Data: (*(*reflect.SliceHeader)(unsafe.Pointer(&amp;bs))).Data, Len: l, &#125;)) if len(s1) != len(s) &#123; b.Error(&quot;error&quot;) &#125; &#125;&#125; String和Slice的底层存储分析reflect.SliceHeader 和reflect.StringHeader123456789type StringHeader struct &#123; Data uintptr Len int&#125;type SliceHeader struct &#123; Data uintptr Len int Cap int&#125; 两者类型基本一样，Slice多了一个Cap，其实这也决定了[]byte可以直接使用指针强转成string，但是反过来却不行 slice的底层存储12345type slice struct &#123; array unsafe.Pointer len int cap int&#125; 以汇编的形式看下slice的底层结构1234package pkg// var data = make([]int, 0, 10)var data = []int&#123;1, 2&#125; 12345678910go tool compile -S pkg.gogo.cuinfo.packagename. SDWARFINFO dupok size=0 0x0000 70 6b 67 pkg&quot;&quot;.data SDATA size=24 0x0000 00 00 00 00 00 00 00 00 02 00 00 00 00 00 00 00 ................ 0x0010 02 00 00 00 00 00 00 00 ........ rel 0+8 t=1 &quot;&quot;..stmp_0+0&quot;&quot;..stmp_0 SNOPTRDATA size=16 0x0000 01 00 00 00 00 00 00 00 02 00 00 00 00 00 00 00 ................... 可以看到””.data 对应的是size是24（8byte的指针，len和cap各自8byte），slice里的内容是两个int对应的就是，””.stmp_0 里的内容 进一步分析data对应的二进制 data+8是02 00 ... ，对应len data+16是02 00 对应cap 整个slice struct在内存里是紧凑分布的，所以我们可以进行指针类的强制转化，类似于c++中reinterpret_cast string的底层结构1234package pkgvar testStr = &quot;abc&quot; 1234567go.cuinfo.packagename. SDWARFINFO dupok size=0 0x0000 70 6b 67 pkggo.string.&quot;abc&quot; SRODATA dupok size=3 0x0000 61 62 63 abc&quot;&quot;.testStr SDATA size=16 0x0000 00 00 00 00 00 00 00 00 03 00 00 00 00 00 00 00 ................ rel 0+8 t=1 go.string.&quot;abc&quot;+0 和上文的slice很类似，size变成了16而已 Fat Pointer像slice这种结构在c中常被称为fatpointer，感兴趣的同学可以参考Go Slices are Fat Pointers 总结 介绍了golang中string，[]byte和[]rune的转化及简单的性能分析 slice在golang中的底层存储","categories":[],"tags":[{"name":"golang slice","slug":"golang-slice","permalink":"https://skyitachi.github.io/tags/golang-slice/"}]},{"title":"二分法的两种实现","slug":"二分法的两种实现","date":"2020-04-14T14:15:38.000Z","updated":"2020-04-14T14:11:39.000Z","comments":true,"path":"2020/04/14/二分法的两种实现/","permalink":"https://skyitachi.github.io/2020/04/14/%E4%BA%8C%E5%88%86%E6%B3%95%E7%9A%84%E4%B8%A4%E7%A7%8D%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"前言虽然二分搜索很简单（在无重复的有序数组上）,但是也有很多值得注意的地方，而且有两种完全不同的写法（两种完全不同的功能） lower bound 找出大于等于target的最小数组下标, 不存在的情况下返回-1 123456789101112131415161718func lower_bound(a []int, target int) int &#123; l := 0 h := len(a) - 1 for l &lt; h &#123; m := l + (h - l) / 2 if a[m] &gt;= target &#123; h = m &#125; else &#123; // l肯定可以取到h值，所以不需要使用向上取整计算m值 l += 1 &#125; &#125; if a[l] &gt;= target &#123; return l &#125; return -1&#125; upper bound 找出小于等于target的最大数组下标 1234567891011121314151617func upper_bound(a []int, target int) int &#123; l := 0 h := len(a) - 1 for l &lt; h &#123; m := l + (h - l + 1) / 2 if a[m] &lt;= target &#123; // l 要能够取到h值，就必须保证m使用向上取整计算, (h - l + 1) / 2 就是这么来的 l = m &#125; else &#123; h = m - 1 &#125; &#125; if a[l] &lt;= target &#123; return l &#125; return -1&#125; 注意点 计算mid的时候不能发生溢出 数组下标不能越界","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://skyitachi.github.io/tags/algorithm/"}]},{"title":"dubbo-go support protobuf","slug":"dubbo-go-protobuf-support","date":"2019-12-29T16:00:00.000Z","updated":"2019-12-29T16:00:00.000Z","comments":true,"path":"2019/12/30/dubbo-go-protobuf-support/","permalink":"https://skyitachi.github.io/2019/12/30/dubbo-go-protobuf-support/","excerpt":"","text":"主要用法 和grpc中使用protobuf生成代码基本一致（至少在形式上）,直接看例子吧 123456789├── go-client│ ├── client.go│ ├── client.yml├── go-server│ ├── main.go│ └── server.yml└── user ├── user.pb.go └── user.proto 1234567891011121314151617syntax = &quot;proto3&quot;;package user;service UserProvider &#123; rpc GetUser (UserRequest) returns (UserReply) &#123;&#125;&#125;message UserRequest &#123; string id = 1;&#125;message UserReply &#123; string id = 1; string name = 2; int32 age = 3;&#125; 使用protoc-gen-dubbogo插件生成dubbogo的代理 1protoc --plugin=&#123;plugin_path&#125; --dubbogo_out=plugins=dubbogo:. user/user.proto client关键代码 1234567user := user.NewUserProvider()reply := user.UserReply&#123;&#125;err := userProvider.GetUser(context.TODO(), &amp;user.UserRequest&#123;Id: &quot;A001&quot;&#125;, &amp;reply)if err != nil &#123; log.Fatal(err)&#125;println(&quot;response result: %+v&quot;, reply) ps: 一切都是熟悉的味道ps: 生成代理的名称需要和reference里配置的一样 server关键代码 12345678910type UserProvider struct &#123; pb.UnimplementedUserProviderServer&#125;func (*UserProvider) GetUser(ctx context.Context, user *pb.UserRequest) (*pb.UserReply, error) &#123; return &amp;pb.UserReply&#123;Id: &quot;001&quot;, Name: &quot;alice&quot;, Age: 18&#125;, nil&#125;// 注册pb.RegisterProvider(new(UserProvider)) 实现原理 在dubbogo抽出一层serialization，任何和serialization相关的之后只要实现Serialize接口就行了，这样是为了更好的实现更多序列化的支持，逻辑上会更合理一些，原有的go hessian2中做了一部分dubbo相关的codec工作，这里我也把它抽到dubbogo中了， 当然hessian2的序列化仍然保留了，这次实现是兼容老版本的。 12345type Serializer interface &#123; Marshal(p DubboPackage) ([]byte, error) Unmarshal([]byte, *DubboPackage) error&#125; 参考了dubbo的protobuf实现，实现了在protobuf层面和java互通（不一定是好事:(） 其他的就是细节了 一些注意点 error的处理和java不太一样，java会把详细的java error stack都返回给客户端，go只会把message传过来，生成一个error 由于java protobuf生成的代理方法名是小写开头(完全搞不明白是为什么)，这在golang中表示私有方法，个人已经提了issue, 所以直接用java的例子是不行的 java protobuf的代理生成的是内部接口，比如xxx$IDemoService, $是url中的一个特殊字符，正好发现了dubbogo的一个注册url的bug 我为什么要支持protobuf protobuf的语言中立性更好，序列化性能也更好 更加符合golang的生态","categories":[],"tags":[{"name":"dubbo, go, protobuf","slug":"dubbo-go-protobuf","permalink":"https://skyitachi.github.io/tags/dubbo-go-protobuf/"}]},{"title":"c++中的传参","slug":"passing-value-in-cpp","date":"2019-08-21T02:30:36.000Z","updated":"2019-08-21T02:30:36.000Z","comments":true,"path":"2019/08/21/passing-value-in-cpp/","permalink":"https://skyitachi.github.io/2019/08/21/passing-value-in-cpp/","excerpt":"","text":"前言最近在用c++写基于libuv的websocket engine的时候发现, 设置callback的参数是一个很有挑战性的工作, 原来觉得c++的复杂在于其模板，oo范式概念的复杂, 现在发现c++的每个方面都很复杂，因为有太多可以通过编译的方式了，我想从传参这个方面切入，让大家了解下c++的复杂（强大）。 ps：本文的传参使基于涉及到动态内存分配对象的传参，一般普通对象的传参基本是不需要考虑这么复杂的(至少我目前这么认为)。 以下是本文中需要传递的参数，一个简单的String, 只保留会讲到的构造函数 1234567891011121314151617class String: &#123; public: String(const char* src): data_(new char[strlen(src) + 1]), size_(strlen(src)) &#123; ::strcpy(data_, src); data_[size_] = 0; &#125; String(const String&amp; lhs): data_(new char[lhs.size() + 1]), size_(lhs.size()) &#123; ::strcpy(data_, lhs.data()); data_[size_] = 0; &#125; // move String(String &amp;&amp;rhs) noexcept: data_(rhs.data_), size_(rhs.size_) &#123; rhs.data_ = nullptr; &#125; &#125;; 我遇到的一个问题是在MessageCallback中，应该使用const String&amp; message还是String&amp;&amp; message, 这两种形参的区别是什么 理解std::move 和右值引用在弄清上述问题之前，还是要从根本上着手，弄清std::move和右值引用。右值引用是c++11中引入的一种新的引用类型，必须要绑定到右值的引用。而std::move的作用是可以把几乎任意值转化成一个右值引用。 123456789101112131415161718void test_passing_value(std::string&amp; s1) &#123; std::cout &lt;&lt; &quot;in the left reference&quot; &lt;&lt; std::endl;&#125;void test_passing_value(std::string&amp;&amp; s1) &#123; std::cout &lt;&lt; &quot;in the right reference&quot; &lt;&lt; std::endl;&#125;std::string s1 = &quot;hello&quot;;std::string &amp;sr = s1;test_passing_value(s1); // in the lefttest_passing_value(std::move(s1)); // in the righttest_passing_value(sr); // in the lefttest_passing_value(std::move(sr)); // in the right// 可以看到无论是左值，还是左值引用，使用std::move之后都可以变成右值引用// 意外的情况就是const T&amp; 在使用std::move转化时的特殊情况 const T&amp; vs T&amp;&amp;c++11中引入了右值引用和move语义，初学者（比如我）很容易被这种特性吸引（move比copy快）, 两者其实是解决不同场景下的问题，T&amp;&amp; 的确提供了一种更为高效的传参方式, 让我们看下两者的细节和使用场景吧。 仅仅使用const T&amp;并不会发生copy 12345678void foo(const String&amp; s) &#123; std::cout &lt;&lt; s &lt;&lt; std::endl;&#125;int main() &#123; String s0(&quot;hello&quot;); foo(s0); // 不会发生复制&#125; const T&amp; 发生复制的情况是在函数体内用到T的local variable， 比如T local = t, 这时候会发生拷贝控制 仅仅使用T&amp;&amp;不会发生move 1234567void f2(String &amp;&amp;s2) &#123; std::cout &lt;&lt; s2 &lt;&lt; std::endl;&#125;int main() &#123; f2(String(&quot;hello&quot;));&#125; 从以上两种情况来看似乎传参的代价都很低，那么应该如何选择呢，主要还是根据语义来做选择，如果你的实参是个左值自然选择第一种，如果是右值那自然是后者，如果你确定需要第二种那么使用std::move也是可以的 结论 由于我在传给callback的string是从buffer中复制构造来的，而不是仅仅像stringpiece那样使用，所以使用右值引用更合适，使用者会放心大胆的使用这个string，move之类的更不在话下了 其他 可以考虑使用StringPiece类似的技术，不过我感觉StringPiece在这个场景下并不好 关于std::move的原理其中涉及到了引用折叠这些比较复杂的概念，所以没有深入介绍 在模板中使用T&amp;&amp; 和实参中的&amp;&amp;还是不一样的，模板中的T&amp;&amp; 在转发参数时要保证不丢失T的信息(T可能是引用) 所以有涉及到了完美转发的概念，std::forward可以解决这个问题","categories":[],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://skyitachi.github.io/tags/cpp/"}]},{"title":"浅谈 javascript 作用域","slug":"scope","date":"2017-04-23T16:00:00.000Z","updated":"2017-04-23T16:00:00.000Z","comments":true,"path":"2017/04/24/scope/","permalink":"https://skyitachi.github.io/2017/04/24/scope/","excerpt":"","text":"前言 本文将主要介绍javascript中作用域相关的问题，尽可能多的使用代码举例说明，尽量少涉及动态作用域相关 词法作用域(核心) javascript的作用域是词法作用域（静态作用域）, 不过像eval，with这些具有动态改变作用域的能力, 本文重点在于词法作用域 1234567891011121314151617181920212223242526272829303132333435363738let a = 1;function testLexicalScope() &#123; console.log(a); // 由于当前scope中a是由最外层定义的，所以此处的a只能访问到最外层的a&#125;function b() &#123; let a = 2; testLexicalScope();&#125;b();// 另一个例子let sameVar1 = 1;let sameVar2 = 1;function outerScope() &#123; let sameVar1 = 2; function innerScope() &#123; console.log(&quot;current scope: sameVar1 is &quot;, sameVar1); // 当前的scope中最近的sameVar1值是2 console.log(&quot;current scope: sameVar2 is &quot;, sameVar2); &#125; innerScope();&#125;outerScope();// current scope: sameVar1 is 2// current scope: sameVar2 is 1//另一个例子const f1 = function () &#123; console.log(outVar);&#125;;let outVar = 1;f1(); // 1 why 只有在函数声明的时候才会遵循lexical scope的规则, 如果是函数表达式则取决于调用的时机 不同类型的作用域(如何创建scope) 函数作用域 属于这个函数的全部变量都可以在整个函数的范围内使用及复用javascript 每个函数都会创建一个scope 12345678function fScope() &#123; var aStr = &quot;function&quot;; console.log(aStr);&#125;fScope();console.log(aStr); // ReferenceError: aStr is not defined 块级作用域({…}) 12345678var foo = true;&#123; // 这里是使用let，将foo绑定到了&#123;&#125;这个块作用域中 let foo = false; let bar = &quot;cannot seen&quot;; console.log(foo); // false&#125;console.log(foo); // trueconsole.log(bar); // ReferenceError var 函数作用域中的var仍然遵循函数作用域相关的 var中没有块级作用域 1234567var foo = true;&#123; var foo = false; var bar = true;&#125;console.log(foo); // falseconsole.log(bar); // bar 变量提升 变量和函数的所有声明多会在任何代码被执行前首先被处理（编译器找到这些变量与合适的作用域关联） 1234567function hoisting() &#123; console.log(a); var a = 1; console.log(a);&#125;hoisting(); 又是let 123456function hoisting() &#123; console.log(a); // 第一个let之上的区域叫做`temporal dead zone` let a = 1; console.log(a);&#125;hoisting(); // ReferenceError 函数声明的优先级会高于变量声明 1234567foo(); // in the functionvar foo = 1;function foo() &#123; console.log(&quot;in the function&quot;);&#125; 总结 关于块级作用域, 可用try{} catch(err) {&#x2F;这里是块级作用域&#x2F;}模拟，更多参考:《你不知道的javascript》上卷中3.4.2节 使用let，const是最佳实践 需要区分函数声明和函数表达式 尽量不要写有提升的代码（声明尽量提前）","categories":[],"tags":[{"name":"javascript","slug":"javascript","permalink":"https://skyitachi.github.io/tags/javascript/"}]}],"categories":[],"tags":[{"name":"algorithm hnsw 向量数据库 faiss hnswlib","slug":"algorithm-hnsw-向量数据库-faiss-hnswlib","permalink":"https://skyitachi.github.io/tags/algorithm-hnsw-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93-faiss-hnswlib/"},{"name":"algorithm hnsw 向量数据库","slug":"algorithm-hnsw-向量数据库","permalink":"https://skyitachi.github.io/tags/algorithm-hnsw-%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"ES, Lucene, elasticsearch","slug":"ES-Lucene-elasticsearch","permalink":"https://skyitachi.github.io/tags/ES-Lucene-elasticsearch/"},{"name":"golang slice","slug":"golang-slice","permalink":"https://skyitachi.github.io/tags/golang-slice/"},{"name":"algorithm","slug":"algorithm","permalink":"https://skyitachi.github.io/tags/algorithm/"},{"name":"dubbo, go, protobuf","slug":"dubbo-go-protobuf","permalink":"https://skyitachi.github.io/tags/dubbo-go-protobuf/"},{"name":"cpp","slug":"cpp","permalink":"https://skyitachi.github.io/tags/cpp/"},{"name":"javascript","slug":"javascript","permalink":"https://skyitachi.github.io/tags/javascript/"}]}