{"meta":{"title":"skyitachi's blog","subtitle":null,"description":"一定要有输出","author":"skyitachi","url":"https://skyitachi.github.io","root":"/"},"pages":[],"posts":[{"title":"Java ByteBuffer实践","slug":"bytebuffer实践","date":"2021-08-13T16:00:00.000Z","updated":"2024-04-14T13:30:30.827Z","comments":true,"path":"2021/08/14/bytebuffer实践/","permalink":"https://skyitachi.github.io/2021/08/14/bytebuffer%E5%AE%9E%E8%B7%B5/","excerpt":"","text":"Java bytebuffer实践前言最近在使用java做文件io相关的代码时，不可避免的使用的filechannel和bytebuffer，其中bytebuffer有些地方容易让初学者产生困扰，这里记录一下我的一些实践 类结构 基本原理我们解释下Buffer类和ByteBuffer中的字段 hb：这个就是实际的byte数组 capacity：就是这个hb实际容量，绝大部分场景下都不可改变，无法增大 offset：内置的偏移量，每次读写buffer都必须加上offset，默认ByteBuffer.allocate的偏移量是0 position: 当前buffer 读写的位置，类似于cursor的概念，默认是0 limit: 当前buffer读写位置的上限，默认是capacity mark：用来记录某个时刻position的位置，默认值是-1 &#x2F;&#x2F; Invariants: mark &lt;&#x3D; position &lt;&#x3D; limit &lt;&#x3D; capacity 向buffer中写入内容: position变大 读取buffer中的内容：当写入完成时此时相当于0到position之间的内容都是刚刚写入的，那应该如何读取呢, 因为读写都是根据position来的，此时需要做一次flip操作，position需要被清零，limit换成之前的position 1234567891011public final Buffer flip() &#123; limit = position; position = 0; mark = -1; return this;&#125; flip操作完之后会发现，limit和capacity之前有可能不一样了，下次在写入buffer的时候能写入的数据变小了 为什么要在写buffer完之后使用flip呢因为写入到buffer中的只有0到position之间的数据，而position和就limit之间的数据是未定义的，不应该被应用程序读到，所以需要将最新的写入position设置为新的limit，这样应用程序读到limit就不读取数据了。 读完之后再写应该怎么处理 假设完全读完了buffer，此时position和limit相等，对于这个buffer来说它的remaining是0了，不存在可写入的空间了，此时可以继续使用flip，当然更好的处理是使用rewind 123456789public final Buffer rewind() &#123; position = 0; mark = -1; return this;&#125; 具体的使用场景 初始化 123456789101112131415// 初始化ByteBuffer buf = ByteBuffer.allocate(4096);public static ByteBuffer allocate(int capacity) &#123; if (capacity &lt; 0) throw new IllegalArgumentException(); return new HeapByteBuffer(capacity, capacity);&#125; 可以看到实际初始化的是HeapByteBuffer实例，因为还有DirectBuffer，不过本文不会涉及 读写buffer 因为Filechannel配合在一起使用，而且经常和文件系统的读写在一个语境中使用，不免有些容易混淆的地方。 从文件系统读取数据到buffer中，即使用fileChannel.read(buf)这个对于buffer来说其实是写入，当然该read会尽可能读满buffer 通过filechannel和bytebuffer读取文件中第一个long number 12345fileChannel.read(buf); // buf会被读满，即position==limitbuf.flip(); // position = 0; limit = old positionbuf.getLong(); // position += 8; 所以我们看到从文件系统中读完之后要flip一下，在使用buf读写的时候要注意尽量读满再使用flip，否则应该使用rewind 通过bytebuffer和filechannel写入一个long number到文件系统中 12345buf.putLong(1L);buf.flip(); // 未写满的情况下，必须使用flip，写满的情况下flip和rewind是等价的fileChannel.write(buf); 总结 容易让人混淆的就是flip使用的时机，理解position和limit的关系之后就会简单不少","categories":[],"tags":[{"name":"实践","slug":"实践","permalink":"https://skyitachi.github.io/tags/%E5%AE%9E%E8%B7%B5/"}]},{"title":"Golang 中[]byte, string和[]rune的相互转化的底层原理和剖析","slug":"golang_slice","date":"2021-02-21T02:15:38.000Z","updated":"2024-04-14T13:30:30.827Z","comments":true,"path":"2021/02/21/golang_slice/","permalink":"https://skyitachi.github.io/2021/02/21/golang_slice/","excerpt":"","text":"Golang 中[]byte, string和[]rune的相互转化的底层原理和剖析在golang中有些场景经常会用到[]byte和string的相互转化，尤其是在使用json.Marshal和json.Unmarshal的时候，经常会遇到需要这种转化。 本文主要说明以下内容： 几种类型相互转化的方法和性能分析 这些类型的底层存储 代码gist 相互转化[]byte和string的相互转化string -&gt; []byte1234567891011121314151617181920212223242526func BenchmarkStringToByteSlice(b *testing.B) &#123; s := genString(10000) b.ReportAllocs() for i := 0; i &lt; b.N; i++ &#123; bs := []byte(s) if len(bs) != len(s) &#123; b.Error(&quot;error&quot;) &#125; &#125;&#125;func BenchmarkStringToByteSliceUnsafe(b *testing.B) &#123; s := genString(10000) b.ReportAllocs() for i := 0; i &lt; b.N; i++ &#123; l := len(s) bs := *(*[]byte)(unsafe.Pointer(&amp;reflect.SliceHeader&#123; Data: (*(*reflect.StringHeader)(unsafe.Pointer(&amp;s))).Data, Len: l, Cap: l, &#125;)) if len(bs) != len(s) &#123; b.Error(&quot;error&quot;) &#125; &#125;&#125; 第一种使用[]byte这种直接转化，也是我们常用的方式，第二种是使用unsafe的方式。这两种区别就在于一个是重新分配了内存，另一个是复用了原来的内存。 benchmark的结果也验证了这一点 12345678910go test -run=BenchmarkStringToByteSlice -bench=StringToByteSlice# go-demo.testgoos: darwingoarch: amd64pkg: go-demoBenchmarkStringToByteSlice-12 1164224 964 ns/op 10285 B/op 1 allocs/opBenchmarkStringToByteSliceUnsafe-12 1000000000 0.380 ns/op 0 B/op 0 allocs/opPASSok go-demo 2.089s []byte -&gt; string12345678910111213141516171819202122func BenchmarkSliceByteToString(b *testing.B) &#123; bs := genSliceByte(100) b.ReportAllocs() for i := 0; i &lt; b.N; i++ &#123; s := string(bs) if len(s) != len(bs) &#123; b.Error(&quot;error&quot;) &#125; &#125;&#125;func BenchmarkSliceByteToStringUnsafe(b *testing.B) &#123; bs := genSliceByte(100) b.ReportAllocs() for i := 0; i &lt; b.N; i++ &#123; s := *(*string)(unsafe.Pointer(&amp;bs)) if len(s) != len(bs) &#123; b.Log(&quot;slice: &quot;, len(bs), &quot; string: &quot;, len(s)) b.Error(&quot;error: &quot;) &#125; &#125;&#125; benchmark 结果 12345678910go test -run=BenchmarkSliceByteToString -bench=SliceByteToString# go-demo.testgoos: darwingoarch: amd64pkg: go-demoBenchmarkSliceByteToString-12 35913873 32.4 ns/op 112 B/op 1 allocs/opBenchmarkSliceByteToStringUnsafe-12 1000000000 0.253 ns/op 0 B/op 0 allocs/opPASSok go-demo 3.796s string和[]rune的相互转化string和rune的相互转化其实和上面类似，主要是[]rune对应的[]byte数组长度需要计算下，这里就只贴一个[]rune到string的转化了 123456789101112131415161718func BenchmarkSliceRuneToStringUnsafe(b *testing.B) &#123; bs := genSliceRune(100) s1 := string(bs) b.ReportAllocs() for i := 0; i &lt; b.N; i++ &#123; var l int for _, r := range bs &#123; l += utf8.RuneLen(r) &#125; s := *(*string)(unsafe.Pointer(&amp;reflect.StringHeader&#123; Data: (*(*reflect.SliceHeader)(unsafe.Pointer(&amp;bs))).Data, Len: l, &#125;)) if len(s1) != len(s) &#123; b.Error(&quot;error&quot;) &#125; &#125;&#125; String和Slice的底层存储分析reflect.SliceHeader 和reflect.StringHeader123456789type StringHeader struct &#123; Data uintptr Len int&#125;type SliceHeader struct &#123; Data uintptr Len int Cap int&#125; 两者类型基本一样，Slice多了一个Cap，其实这也决定了[]byte可以直接使用指针强转成string，但是反过来却不行 slice的底层存储12345type slice struct &#123; array unsafe.Pointer len int cap int&#125; 以汇编的形式看下slice的底层结构1234package pkg// var data = make([]int, 0, 10)var data = []int&#123;1, 2&#125; 12345678910go tool compile -S pkg.gogo.cuinfo.packagename. SDWARFINFO dupok size=0 0x0000 70 6b 67 pkg&quot;&quot;.data SDATA size=24 0x0000 00 00 00 00 00 00 00 00 02 00 00 00 00 00 00 00 ................ 0x0010 02 00 00 00 00 00 00 00 ........ rel 0+8 t=1 &quot;&quot;..stmp_0+0&quot;&quot;..stmp_0 SNOPTRDATA size=16 0x0000 01 00 00 00 00 00 00 00 02 00 00 00 00 00 00 00 ................... 可以看到””.data 对应的是size是24（8byte的指针，len和cap各自8byte），slice里的内容是两个int对应的就是，””.stmp_0 里的内容 进一步分析data对应的二进制 data+8是02 00 ... ，对应len data+16是02 00 对应cap 整个slice struct在内存里是紧凑分布的，所以我们可以进行指针类的强制转化，类似于c++中reinterpret_cast string的底层结构1234package pkgvar testStr = &quot;abc&quot; 1234567go.cuinfo.packagename. SDWARFINFO dupok size=0 0x0000 70 6b 67 pkggo.string.&quot;abc&quot; SRODATA dupok size=3 0x0000 61 62 63 abc&quot;&quot;.testStr SDATA size=16 0x0000 00 00 00 00 00 00 00 00 03 00 00 00 00 00 00 00 ................ rel 0+8 t=1 go.string.&quot;abc&quot;+0 和上文的slice很类似，size变成了16而已 Fat Pointer像slice这种结构在c中常被称为fatpointer，感兴趣的同学可以参考Go Slices are Fat Pointers 总结 介绍了golang中string，[]byte和[]rune的转化及简单的性能分析 slice在golang中的底层存储","categories":[],"tags":[{"name":"golang slice","slug":"golang-slice","permalink":"https://skyitachi.github.io/tags/golang-slice/"}]},{"title":"2020年度总结","slug":"2020年度总结","date":"2021-01-09T16:00:00.000Z","updated":"2024-04-14T13:30:30.827Z","comments":true,"path":"2021/01/10/2020年度总结/","permalink":"https://skyitachi.github.io/2021/01/10/2020%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/","excerpt":"","text":"2020年终总结整体而言2020对我来讲是一个比较跌宕起伏的一年，带给我的影响大到我这种从来不写总结的人也想写一写这一年来的变化。 整体变化 老东家解体，工作从杭州来到了上海 工作的title从前端技术专家变成了普通golang后端开发，但是整体工作内容上感觉没有差多少 选择了教育行业 这些变化有些是主动的，有些是被动的，大部分是被动的，就像我一直以来的那样，不是很主动，总认为事情得百分百准备好才能开始，事实上根本就没有这样的情况出现过。 先说下时间线总结吧，平常会有写日记的习惯，所以整理起来也不是很困难，整理完了明显发现很乱，不够聚焦。 时间线总结 1月：rocksdb和level的源码阅读；dynamodb，wisckeydb，hashkv，bigtable论文阅读 2月：wiskeydb的实现；badger源码学习，titandb的源码阅读，面试的整理；cmu15-445部分学习 3月：cmu15-445的 concurrency control学习；percolater，tikv，etcd，phxpaxos学习；分布式系统的面试准备 4月：面试和面试准备，包括rocketmq，redis，libuv，reactor，golang调度模型，websocket server的学习，以及第一次面试的惨败和滴滴kv组面试让我看到了自己欠缺的东西，及时调整了方向为后端开发 5月：mysql，blackwidow，redis，codis的学习，面试了一家北京的创业公司，和创始人谈的还是比较不错的，准备入职。。。 6月：通过了另一个部门的面试，加入新公司，开启正式的后端开发生涯 7月：上线自己的第一个系统 8月：mysql源码阅读尝试（尝试未果），blackwidow学习，开始yedis zset btree index的实践 9月：btree index的实践，分裂算法的学习 10月：btree index的实践 11月：btree index的并发控制不知道如何解决，选择了cmu15445的课程实践 12月：bustub实践：完成project0，project1，project2#checkpoint1的测试 当我整理完时间线后，感觉就是一个字”杂“，年初不停的看论文，但是效果很不好，没有带场景的去看，看bigtable的时候甚至不知道hbase就是bigtable的开源实现。 理解比较深的就是wisckeydb，leveldb和rocksdb相关源码，但是也没有到达那种高屋建瓴的地步，主要原因就是没有相关的实践，c++的功底太弱（直接导致滴滴kv组的三面被拒）。 最终在4月份的时候由于感觉在分布式系统，存储引擎方向的积累还不够，就选择了准备后端开发，整体上手还是比较快的，但是感觉经验不够，不像在nodejs方向上游刃有余。 话说回来为什么要在工作6年后选择换方向，其实主要是感觉nodejs方向上可做的东西比较少，在整个业务上也不是核心的地位，nodejs虽然能做微服务，但是java才是主流。优先选的是分布式系统方向，但是发现积累不够，很多东西学的不够扎实，虽然阿里中间件比赛上能够有所收获，但是在整体上开始差很多，不过总算是入门了吧。 问题 学习不求甚解，贪多而不精（客观上时间来不及，主观上心态出了问题），上半年的时间上就可以看出来，学了那么多东西，但是真正能融汇贯通的很少。 学习习惯不好，总想一口吃成胖子，不能对自己的实力有客观的评价（时而过高时而过低），根本原因在于实践太少。 抗压能力不够，很多事情总希望一个人解决，没有把问题及早的抛出来（虽然现在不知道抛出来管不管用），不愿意分享真实想法，心态太容易崩了。 对业界行情了解不够，算是没有什么眼界吧，跳出来之后感觉自己就像井底之蛙。 不够目标导向。 表达能力堪忧，无论是口头的还是文字上的，都显得有些业余。 收获 分布式系统和存储引擎的入门让我在新公司的整体技术架构上比较熟悉，能够大致了解基础架构，中间件的原理和使用 实现yedis的btree和bustub中才感觉真正能用c++写点东西了 和同学的交流变多，认清了当前自己的水平 改进 注重实践，从btree这一个点上突破存储引擎，存储引擎突破了之后再考虑分布式的事情。 持续改进学习习惯，给自己创造能够持续学习的时间段。 平衡好工作和自己的学习，优先高标准的完成工作，有余力再投入到自己的学习中，像分布式系统，mysql这种在工作中就可以学习。 持续产出文章，学习要有阶段性的总结。 再谈目标 能够用c++实现yedis，支持分布式架构 每两周一篇blog golang的源码阅读 熟练使用java和spring 未来 道阻且长，全力以赴 既往不咎，纵情向前","categories":[],"tags":[{"name":"总结","slug":"总结","permalink":"https://skyitachi.github.io/tags/%E6%80%BB%E7%BB%93/"}]},{"title":"BTree Leaf Node分裂问题","slug":"btree leaf node的分裂记录","date":"2020-12-18T16:00:00.000Z","updated":"2024-04-14T13:30:30.827Z","comments":true,"path":"2020/12/19/btree leaf node的分裂记录/","permalink":"https://skyitachi.github.io/2020/12/19/btree%20leaf%20node%E7%9A%84%E5%88%86%E8%A3%82%E8%AE%B0%E5%BD%95/","excerpt":"","text":"BTree Leaf Node分裂问题记录这两天在做BTree的实现的时候被一个问题困住了，就是BPlusTreeInternalPage的分裂问题 cmu15445中，BPlusTreeInternalPage 只提供了一个MoveHalfTo的操作，这在我看来是不够用的 先看下bustub的api 1234567void MoveAllTo(BPlusTreeInternalPage *recipient, const KeyType &amp;middle_key, BufferPoolManager *buffer_pool_manager);void MoveHalfTo(BPlusTreeInternalPage *recipient, BufferPoolManager *buffer_pool_manager);void MoveFirstToEndOf(BPlusTreeInternalPage *recipient, const KeyType &amp;middle_key, BufferPoolManager *buffer_pool_manager);void MoveLastToFrontOf(BPlusTreeInternalPage *recipient, const KeyType &amp;middle_key, BufferPoolManager *buffer_pool_manager); 而我在yedis中写的btree 中internalnode会把midkey提到parent上以保持btree的特性 1BTreeNodePage* index_split(BufferPoolManager*, BTreeNodePage* parent, int child_idx); 解释下两种api的作用 bustub 分裂之后 bustub中第一个key都是无效的，所以能保证ki &gt; (k in pi) 这种分裂乍看起来第二页多了一个key，后续在这个page上insert,让我感觉有点不对劲，事实上只要忽略第一个key就好了，本例子中直接忽略k2 yedis的分裂 我会主动把mid-key剔除出去（要插入到parent中），这样看起来就干净有点了，事实上两者没什么区别。 这只是一个思维上的转变，bustub的抽象更好些，yedis中的操作api都是太零散了，继续加油","categories":[],"tags":[{"name":"cmu15445 btree cpp","slug":"cmu15445-btree-cpp","permalink":"https://skyitachi.github.io/tags/cmu15445-btree-cpp/"}]},{"title":"二分法的两种实现","slug":"二分法的两种实现","date":"2020-04-14T14:15:38.000Z","updated":"2020-04-14T14:11:39.000Z","comments":true,"path":"2020/04/14/二分法的两种实现/","permalink":"https://skyitachi.github.io/2020/04/14/%E4%BA%8C%E5%88%86%E6%B3%95%E7%9A%84%E4%B8%A4%E7%A7%8D%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"前言虽然二分搜索很简单（在无重复的有序数组上）,但是也有很多值得注意的地方，而且有两种完全不同的写法（两种完全不同的功能） lower bound 找出大于等于target的最小数组下标, 不存在的情况下返回-1 123456789101112131415161718func lower_bound(a []int, target int) int &#123; l := 0 h := len(a) - 1 for l &lt; h &#123; m := l + (h - l) / 2 if a[m] &gt;= target &#123; h = m &#125; else &#123; // l肯定可以取到h值，所以不需要使用向上取整计算m值 l += 1 &#125; &#125; if a[l] &gt;= target &#123; return l &#125; return -1&#125; upper bound 找出小于等于target的最大数组下标 1234567891011121314151617func upper_bound(a []int, target int) int &#123; l := 0 h := len(a) - 1 for l &lt; h &#123; m := l + (h - l + 1) / 2 if a[m] &lt;= target &#123; // l 要能够取到h值，就必须保证m使用向上取整计算, (h - l + 1) / 2 就是这么来的 l = m &#125; else &#123; h = m - 1 &#125; &#125; if a[l] &lt;= target &#123; return l &#125; return -1&#125; 注意点 计算mid的时候不能发生溢出 数组下标不能越界","categories":[],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://skyitachi.github.io/tags/algorithm/"}]},{"title":"dubbo-go support protobuf","slug":"dubbo-go-protobuf-support","date":"2019-12-29T16:00:00.000Z","updated":"2024-04-14T13:30:30.827Z","comments":true,"path":"2019/12/30/dubbo-go-protobuf-support/","permalink":"https://skyitachi.github.io/2019/12/30/dubbo-go-protobuf-support/","excerpt":"","text":"主要用法 和grpc中使用protobuf生成代码基本一致（至少在形式上）,直接看例子吧 123456789├── go-client│ ├── client.go│ ├── client.yml├── go-server│ ├── main.go│ └── server.yml└── user ├── user.pb.go └── user.proto 1234567891011121314151617syntax = &quot;proto3&quot;;package user;service UserProvider &#123; rpc GetUser (UserRequest) returns (UserReply) &#123;&#125;&#125;message UserRequest &#123; string id = 1;&#125;message UserReply &#123; string id = 1; string name = 2; int32 age = 3;&#125; 使用protoc-gen-dubbogo插件生成dubbogo的代理 1protoc --plugin=&#123;plugin_path&#125; --dubbogo_out=plugins=dubbogo:. user/user.proto client关键代码 1234567user := user.NewUserProvider()reply := user.UserReply&#123;&#125;err := userProvider.GetUser(context.TODO(), &amp;user.UserRequest&#123;Id: &quot;A001&quot;&#125;, &amp;reply)if err != nil &#123; log.Fatal(err)&#125;println(&quot;response result: %+v&quot;, reply) ps: 一切都是熟悉的味道ps: 生成代理的名称需要和reference里配置的一样 server关键代码 12345678910type UserProvider struct &#123; pb.UnimplementedUserProviderServer&#125;func (*UserProvider) GetUser(ctx context.Context, user *pb.UserRequest) (*pb.UserReply, error) &#123; return &amp;pb.UserReply&#123;Id: &quot;001&quot;, Name: &quot;alice&quot;, Age: 18&#125;, nil&#125;// 注册pb.RegisterProvider(new(UserProvider)) 实现原理 在dubbogo抽出一层serialization，任何和serialization相关的之后只要实现Serialize接口就行了，这样是为了更好的实现更多序列化的支持，逻辑上会更合理一些，原有的go hessian2中做了一部分dubbo相关的codec工作，这里我也把它抽到dubbogo中了， 当然hessian2的序列化仍然保留了，这次实现是兼容老版本的。 12345type Serializer interface &#123; Marshal(p DubboPackage) ([]byte, error) Unmarshal([]byte, *DubboPackage) error&#125; 参考了dubbo的protobuf实现，实现了在protobuf层面和java互通（不一定是好事:(） 其他的就是细节了 一些注意点 error的处理和java不太一样，java会把详细的java error stack都返回给客户端，go只会把message传过来，生成一个error 由于java protobuf生成的代理方法名是小写开头(完全搞不明白是为什么)，这在golang中表示私有方法，个人已经提了issue, 所以直接用java的例子是不行的 java protobuf的代理生成的是内部接口，比如xxx$IDemoService, $是url中的一个特殊字符，正好发现了dubbogo的一个注册url的bug 我为什么要支持protobuf protobuf的语言中立性更好，序列化性能也更好 更加符合golang的生态","categories":[],"tags":[{"name":"dubbo, go, protobuf","slug":"dubbo-go-protobuf","permalink":"https://skyitachi.github.io/tags/dubbo-go-protobuf/"}]},{"title":"c++中的传参","slug":"passing-value-in-cpp","date":"2019-08-21T02:30:36.000Z","updated":"2024-04-14T13:30:30.827Z","comments":true,"path":"2019/08/21/passing-value-in-cpp/","permalink":"https://skyitachi.github.io/2019/08/21/passing-value-in-cpp/","excerpt":"","text":"前言最近在用c++写基于libuv的websocket engine的时候发现, 设置callback的参数是一个很有挑战性的工作, 原来觉得c++的复杂在于其模板，oo范式概念的复杂, 现在发现c++的每个方面都很复杂，因为有太多可以通过编译的方式了，我想从传参这个方面切入，让大家了解下c++的复杂（强大）。 ps：本文的传参使基于涉及到动态内存分配对象的传参，一般普通对象的传参基本是不需要考虑这么复杂的(至少我目前这么认为)。 以下是本文中需要传递的参数，一个简单的String, 只保留会讲到的构造函数 1234567891011121314151617class String: &#123; public: String(const char* src): data_(new char[strlen(src) + 1]), size_(strlen(src)) &#123; ::strcpy(data_, src); data_[size_] = 0; &#125; String(const String&amp; lhs): data_(new char[lhs.size() + 1]), size_(lhs.size()) &#123; ::strcpy(data_, lhs.data()); data_[size_] = 0; &#125; // move String(String &amp;&amp;rhs) noexcept: data_(rhs.data_), size_(rhs.size_) &#123; rhs.data_ = nullptr; &#125; &#125;; 我遇到的一个问题是在MessageCallback中，应该使用const String&amp; message还是String&amp;&amp; message, 这两种形参的区别是什么 理解std::move 和右值引用在弄清上述问题之前，还是要从根本上着手，弄清std::move和右值引用。右值引用是c++11中引入的一种新的引用类型，必须要绑定到右值的引用。而std::move的作用是可以把几乎任意值转化成一个右值引用。 123456789101112131415161718void test_passing_value(std::string&amp; s1) &#123; std::cout &lt;&lt; &quot;in the left reference&quot; &lt;&lt; std::endl;&#125;void test_passing_value(std::string&amp;&amp; s1) &#123; std::cout &lt;&lt; &quot;in the right reference&quot; &lt;&lt; std::endl;&#125;std::string s1 = &quot;hello&quot;;std::string &amp;sr = s1;test_passing_value(s1); // in the lefttest_passing_value(std::move(s1)); // in the righttest_passing_value(sr); // in the lefttest_passing_value(std::move(sr)); // in the right// 可以看到无论是左值，还是左值引用，使用std::move之后都可以变成右值引用// 意外的情况就是const T&amp; 在使用std::move转化时的特殊情况 const T&amp; vs T&amp;&amp;c++11中引入了右值引用和move语义，初学者（比如我）很容易被这种特性吸引（move比copy快）, 两者其实是解决不同场景下的问题，T&amp;&amp; 的确提供了一种更为高效的传参方式, 让我们看下两者的细节和使用场景吧。 仅仅使用const T&amp;并不会发生copy 12345678void foo(const String&amp; s) &#123; std::cout &lt;&lt; s &lt;&lt; std::endl;&#125;int main() &#123; String s0(&quot;hello&quot;); foo(s0); // 不会发生复制&#125; const T&amp; 发生复制的情况是在函数体内用到T的local variable， 比如T local = t, 这时候会发生拷贝控制 仅仅使用T&amp;&amp;不会发生move 1234567void f2(String &amp;&amp;s2) &#123; std::cout &lt;&lt; s2 &lt;&lt; std::endl;&#125;int main() &#123; f2(String(&quot;hello&quot;));&#125; 从以上两种情况来看似乎传参的代价都很低，那么应该如何选择呢，主要还是根据语义来做选择，如果你的实参是个左值自然选择第一种，如果是右值那自然是后者，如果你确定需要第二种那么使用std::move也是可以的 结论 由于我在传给callback的string是从buffer中复制构造来的，而不是仅仅像stringpiece那样使用，所以使用右值引用更合适，使用者会放心大胆的使用这个string，move之类的更不在话下了 其他 可以考虑使用StringPiece类似的技术，不过我感觉StringPiece在这个场景下并不好 关于std::move的原理其中涉及到了引用折叠这些比较复杂的概念，所以没有深入介绍 在模板中使用T&amp;&amp; 和实参中的&amp;&amp;还是不一样的，模板中的T&amp;&amp; 在转发参数时要保证不丢失T的信息(T可能是引用) 所以有涉及到了完美转发的概念，std::forward可以解决这个问题","categories":[],"tags":[{"name":"cpp","slug":"cpp","permalink":"https://skyitachi.github.io/tags/cpp/"}]},{"title":"浅谈 javascript 作用域","slug":"scope","date":"2017-04-23T16:00:00.000Z","updated":"2024-04-14T13:30:30.827Z","comments":true,"path":"2017/04/24/scope/","permalink":"https://skyitachi.github.io/2017/04/24/scope/","excerpt":"","text":"前言 本文将主要介绍javascript中作用域相关的问题，尽可能多的使用代码举例说明，尽量少涉及动态作用域相关 词法作用域(核心) javascript的作用域是词法作用域（静态作用域）, 不过像eval，with这些具有动态改变作用域的能力, 本文重点在于词法作用域 1234567891011121314151617181920212223242526272829303132333435363738let a = 1;function testLexicalScope() &#123; console.log(a); // 由于当前scope中a是由最外层定义的，所以此处的a只能访问到最外层的a&#125;function b() &#123; let a = 2; testLexicalScope();&#125;b();// 另一个例子let sameVar1 = 1;let sameVar2 = 1;function outerScope() &#123; let sameVar1 = 2; function innerScope() &#123; console.log(&quot;current scope: sameVar1 is &quot;, sameVar1); // 当前的scope中最近的sameVar1值是2 console.log(&quot;current scope: sameVar2 is &quot;, sameVar2); &#125; innerScope();&#125;outerScope();// current scope: sameVar1 is 2// current scope: sameVar2 is 1//另一个例子const f1 = function () &#123; console.log(outVar);&#125;;let outVar = 1;f1(); // 1 why 只有在函数声明的时候才会遵循lexical scope的规则, 如果是函数表达式则取决于调用的时机 不同类型的作用域(如何创建scope) 函数作用域 属于这个函数的全部变量都可以在整个函数的范围内使用及复用javascript 每个函数都会创建一个scope 12345678function fScope() &#123; var aStr = &quot;function&quot;; console.log(aStr);&#125;fScope();console.log(aStr); // ReferenceError: aStr is not defined 块级作用域({…}) 12345678var foo = true;&#123; // 这里是使用let，将foo绑定到了&#123;&#125;这个块作用域中 let foo = false; let bar = &quot;cannot seen&quot;; console.log(foo); // false&#125;console.log(foo); // trueconsole.log(bar); // ReferenceError var 函数作用域中的var仍然遵循函数作用域相关的 var中没有块级作用域 1234567var foo = true;&#123; var foo = false; var bar = true;&#125;console.log(foo); // falseconsole.log(bar); // bar 变量提升 变量和函数的所有声明多会在任何代码被执行前首先被处理（编译器找到这些变量与合适的作用域关联） 1234567function hoisting() &#123; console.log(a); var a = 1; console.log(a);&#125;hoisting(); 又是let 123456function hoisting() &#123; console.log(a); // 第一个let之上的区域叫做`temporal dead zone` let a = 1; console.log(a);&#125;hoisting(); // ReferenceError 函数声明的优先级会高于变量声明 1234567foo(); // in the functionvar foo = 1;function foo() &#123; console.log(&quot;in the function&quot;);&#125; 总结 关于块级作用域, 可用try{} catch(err) {&#x2F;这里是块级作用域&#x2F;}模拟，更多参考:《你不知道的javascript》上卷中3.4.2节 使用let，const是最佳实践 需要区分函数声明和函数表达式 尽量不要写有提升的代码（声明尽量提前）","categories":[],"tags":[{"name":"javascript","slug":"javascript","permalink":"https://skyitachi.github.io/tags/javascript/"}]}],"categories":[],"tags":[{"name":"实践","slug":"实践","permalink":"https://skyitachi.github.io/tags/%E5%AE%9E%E8%B7%B5/"},{"name":"golang slice","slug":"golang-slice","permalink":"https://skyitachi.github.io/tags/golang-slice/"},{"name":"总结","slug":"总结","permalink":"https://skyitachi.github.io/tags/%E6%80%BB%E7%BB%93/"},{"name":"cmu15445 btree cpp","slug":"cmu15445-btree-cpp","permalink":"https://skyitachi.github.io/tags/cmu15445-btree-cpp/"},{"name":"algorithm","slug":"algorithm","permalink":"https://skyitachi.github.io/tags/algorithm/"},{"name":"dubbo, go, protobuf","slug":"dubbo-go-protobuf","permalink":"https://skyitachi.github.io/tags/dubbo-go-protobuf/"},{"name":"cpp","slug":"cpp","permalink":"https://skyitachi.github.io/tags/cpp/"},{"name":"javascript","slug":"javascript","permalink":"https://skyitachi.github.io/tags/javascript/"}]}